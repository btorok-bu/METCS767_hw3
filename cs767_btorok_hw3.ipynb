{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2833d135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "metric = tf.keras.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410dfc1",
   "metadata": {},
   "source": [
    "The new structure of the dataset requires extensive reworking of the code in order to use daily prices instead of rollup information. The code was updated to simplify the label process by using an average momentum score instead of a custom momentum implementaion and explicit labeling of columns was rolled up into loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "985cc7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create new label based on stock performance relative to other stocks and benchmark\n",
    "# Use the direct path to the file in the environment\n",
    "input_file = 'sp1500_company_with_history_wide.csv'\n",
    "benchmark_input_file = 'benchmark_history.csv'\n",
    "df_raw = pd.read_csv(input_file)\n",
    "\n",
    "benchmark_df = pd.read_csv(benchmark_input_file, parse_dates=['date'])\n",
    "# protect against errors when computing pairwise daily returns\n",
    "benchmark_df = benchmark_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "# convert date to YYYMMDD to match wide column suffixes\n",
    "benchmark_df['date_key'] = benchmark_df['date'].dt.strftime(\"%Y%m%d\")\n",
    "\n",
    "# map the date_key to benchmark close price\n",
    "benchmark_close = benchmark_df.set_index('date_key')['close']\n",
    "\n",
    "# use log return - measurement of investment performance by ratio of final price to initial price\n",
    "def log_return(final, initial):\n",
    "    return np.log(final / initial)\n",
    "\n",
    "\n",
    "# calculate z score for performance relative to others in each window\n",
    "def zscore(s: pd.Series) -> pd.Series:\n",
    "    mu = s.mean(skipna=True)\n",
    "    sd = s.std(ddof=0, skipna=True)\n",
    "    return (s - mu) / sd\n",
    "\n",
    "# determine which dates exist in benchmark and company data\n",
    "\n",
    "all_close_cols = [c for c in df_raw.columns if c.startswith(\"close_\")]\n",
    "\n",
    "# extract YYYMMDD part from close\n",
    "company_dates = {c.split(\"_\", 1)[1] for c in all_close_cols}\n",
    "\n",
    "# keep only dates that are both in benchmark and company history\n",
    "trade_days = [d for d in benchmark_df['date_key'] if d in company_dates]\n",
    "\n",
    "# build relative daily returns feature in loop\n",
    "rel_cols = []\n",
    "\n",
    "for prev_key, curr_key in zip(trade_days[:-1], trade_days[1:]):\n",
    "    close_prev = f\"close_{prev_key}\"\n",
    "    close_curr = f\"close_{curr_key}\"\n",
    "\n",
    "    # name of new feature for relative return\n",
    "    feature_name = f\"rel_ret{curr_key}\"\n",
    "\n",
    "    # stock daily log-return for the day\n",
    "    stock_ret = log_return(df_raw[close_curr], df_raw[close_prev])\n",
    "\n",
    "    # benchmark daily log-return for that day\n",
    "    bench_ret = log_return(benchmark_close[curr_key], benchmark_close[prev_key])\n",
    "\n",
    "\n",
    "    # relative performance vs benchmark\n",
    "    df_raw[feature_name] = stock_ret - bench_ret\n",
    "    rel_cols.append(feature_name)\n",
    "\n",
    "\n",
    "# now compute z-score for each daily relative-return\n",
    "\n",
    "z_cols = []\n",
    "\n",
    "for col in rel_cols:\n",
    "    z_name = f\"z_{col}\"\n",
    "    df_raw[z_name] = zscore(df_raw[col])\n",
    "    z_cols.append(z_name)\n",
    "\n",
    "\n",
    "# build 30 day momentum score and label\n",
    "z_df = df_raw[z_cols].copy()\n",
    "\n",
    "# simple momentum measure: mean of per-day z-scores\n",
    "momentum = z_df.mean(axis=1, skipna=True)\n",
    "\n",
    "pct = momentum.rank(pct=True, method='average')\n",
    "\n",
    "df_with_label = df_raw.copy()\n",
    "\n",
    "# add labels based on percentage change\n",
    "df_with_label['label'] = pd.cut(pct, \n",
    "                                bins=[-np.inf, 0.33, 0.66, np.inf],\n",
    "                                labels=[0, 1, 2])\n",
    "\n",
    "# drop Nans and cast label to int\n",
    "df_with_label = df_with_label.dropna(subset=['label']).copy()\n",
    "df_with_label['label'] = df_with_label['label'].astype('int32')\n",
    "\n",
    "\n",
    "# add distance to 52 week extremes\n",
    "rng = (df_with_label['fiftyTwoWeekHigh'] - df_with_label['fiftyTwoWeekLow']).replace(0, np.nan)\n",
    "df_with_label['pos_in_52w'] = (df_with_label['currentPrice'] - df_with_label['fiftyTwoWeekLow']) / (rng + 1e-9)\n",
    "\n",
    "# add distance to moving averages\n",
    "df_with_label['dist_ma50']  = (df_with_label['currentPrice'] - df_with_label['fiftyDayAverage']) / (df_with_label['fiftyDayAverage'] + 1e-9)\n",
    "df_with_label['dist_ma200'] = (df_with_label['currentPrice'] - df_with_label['twoHundredDayAverage']) / (df_with_label['twoHundredDayAverage'] + 1e-9)\n",
    "df_with_label['ma_cross']   = (df_with_label['fiftyDayAverage'] - df_with_label['twoHundredDayAverage']) / (df_with_label['twoHundredDayAverage'] + 1e-9)\n",
    "\n",
    "# add liquidity size, shares outstanding ratios\n",
    "df_with_label['log_mcap']  = np.log(df_with_label['marketCap'] + 1)\n",
    "# high outstanding shares = lots of flots is short and performance may be poor\n",
    "df_with_label['float_to_out'] = df_with_label['floatShares'] / (df_with_label['sharesOutstanding'] + 1e-9)\n",
    "\n",
    "# add z scores to the table for neural net to see each z score\n",
    "for z_name in z_cols:\n",
    "    df_with_label[z_name] = df_raw[z_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab915eac",
   "metadata": {},
   "source": [
    "Now use the same clean data function to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8f082f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2\n",
      "1     0\n",
      "2     1\n",
      "3     2\n",
      "4     2\n",
      "5     1\n",
      "6     2\n",
      "7     1\n",
      "8     1\n",
      "9     2\n",
      "10    0\n",
      "11    2\n",
      "12    2\n",
      "13    2\n",
      "14    0\n",
      "15    2\n",
      "16    0\n",
      "17    1\n",
      "18    1\n",
      "19    2\n",
      "Name: label, dtype: int32\n",
      "['city', 'state', 'zip', 'country', 'industry', 'industryKey', 'industryDisp', 'sector', 'sectorKey', 'sectorDisp', 'fullTimeEmployees', 'auditRisk', 'boardRisk', 'compensationRisk', 'shareHolderRightsRisk', 'overallRisk', 'governanceEpochDate', 'compensationAsOfEpochDate', 'executiveTeam', 'maxAge', 'priceHint', 'previousClose', 'open', 'dayLow', 'dayHigh', 'regularMarketPreviousClose', 'regularMarketOpen', 'regularMarketDayLow', 'regularMarketDayHigh', 'dividendRate', 'dividendYield', 'exDividendDate', 'payoutRatio', 'fiveYearAvgDividendYield', 'beta', 'trailingPE', 'forwardPE', 'volume', 'regularMarketVolume', 'averageVolume', 'averageVolume10days', 'averageDailyVolume10Day', 'bid', 'ask', 'bidSize', 'askSize', 'marketCap', 'fiftyTwoWeekLow', 'fiftyTwoWeekHigh', 'allTimeHigh', 'allTimeLow', 'priceToSalesTrailing12Months', 'fiftyDayAverage', 'twoHundredDayAverage', 'trailingAnnualDividendRate', 'trailingAnnualDividendYield', 'currency', 'enterpriseValue', 'profitMargins', 'floatShares', 'sharesOutstanding', 'sharesShort', 'sharesShortPriorMonth', 'sharesShortPreviousMonthDate', 'dateShortInterest', 'sharesPercentSharesOut', 'heldPercentInsiders', 'heldPercentInstitutions', 'shortRatio', 'shortPercentOfFloat', 'impliedSharesOutstanding', 'bookValue', 'priceToBook', 'lastFiscalYearEnd', 'nextFiscalYearEnd', 'mostRecentQuarter', 'earningsQuarterlyGrowth', 'netIncomeToCommon', 'trailingEps', 'forwardEps', 'enterpriseToRevenue', 'enterpriseToEbitda', '52WeekChange', 'SandP52WeekChange', 'lastDividendValue', 'lastDividendDate', 'currentPrice', 'targetHighPrice', 'targetLowPrice', 'targetMeanPrice', 'targetMedianPrice', 'recommendationMean', 'recommendationKey', 'numberOfAnalystOpinions', 'totalCash', 'totalCashPerShare', 'ebitda', 'totalDebt', 'quickRatio', 'currentRatio', 'totalRevenue', 'debtToEquity', 'revenuePerShare', 'returnOnAssets', 'returnOnEquity', 'grossProfits', 'freeCashflow', 'operatingCashflow', 'earningsGrowth', 'revenueGrowth', 'grossMargins', 'ebitdaMargins', 'operatingMargins', 'financialCurrency', 'symbol', 'typeDisp', 'postMarketTime', 'regularMarketTime', 'exchange', 'regularMarketChangePercent', 'regularMarketPrice', 'firstTradeDateMilliseconds', 'postMarketChangePercent', 'postMarketPrice', 'postMarketChange', 'regularMarketChange', 'regularMarketDayRange', 'fullExchangeName', 'averageDailyVolume3Month', 'fiftyTwoWeekLowChange', 'fiftyTwoWeekLowChangePercent', 'fiftyTwoWeekRange', 'fiftyTwoWeekHighChange', 'fiftyTwoWeekHighChangePercent', 'fiftyTwoWeekChangePercent', 'dividendDate', 'earningsTimestamp', 'earningsTimestampStart', 'earningsTimestampEnd', 'earningsCallTimestampStart', 'earningsCallTimestampEnd', 'isEarningsDateEstimate', 'epsTrailingTwelveMonths', 'epsForward', 'epsCurrentYear', 'priceEpsCurrentYear', 'fiftyDayAverageChange', 'fiftyDayAverageChangePercent', 'twoHundredDayAverageChange', 'twoHundredDayAverageChangePercent', 'averageAnalystRating', 'open_20251006', 'open_20251007', 'open_20251008', 'open_20251009', 'open_20251010', 'open_20251013', 'open_20251014', 'open_20251015', 'open_20251016', 'open_20251017', 'open_20251020', 'open_20251021', 'open_20251022', 'open_20251023', 'open_20251024', 'open_20251027', 'open_20251028', 'open_20251029', 'open_20251030', 'open_20251031', 'open_20251103', 'open_20251104', 'open_20251105', 'open_20251106', 'open_20251107', 'open_20251110', 'open_20251111', 'open_20251112', 'open_20251113', 'open_20251114', 'high_20251006', 'high_20251007', 'high_20251008', 'high_20251009', 'high_20251010', 'high_20251013', 'high_20251014', 'high_20251015', 'high_20251016', 'high_20251017', 'high_20251020', 'high_20251021', 'high_20251022', 'high_20251023', 'high_20251024', 'high_20251027', 'high_20251028', 'high_20251029', 'high_20251030', 'high_20251031', 'high_20251103', 'high_20251104', 'high_20251105', 'high_20251106', 'high_20251107', 'high_20251110', 'high_20251111', 'high_20251112', 'high_20251113', 'high_20251114', 'low_20251006', 'low_20251007', 'low_20251008', 'low_20251009', 'low_20251010', 'low_20251013', 'low_20251014', 'low_20251015', 'low_20251016', 'low_20251017', 'low_20251020', 'low_20251021', 'low_20251022', 'low_20251023', 'low_20251024', 'low_20251027', 'low_20251028', 'low_20251029', 'low_20251030', 'low_20251031', 'low_20251103', 'low_20251104', 'low_20251105', 'low_20251106', 'low_20251107', 'low_20251110', 'low_20251111', 'low_20251112', 'low_20251113', 'low_20251114', 'close_20251006', 'close_20251007', 'close_20251008', 'close_20251009', 'close_20251010', 'close_20251013', 'close_20251014', 'close_20251015', 'close_20251016', 'close_20251017', 'close_20251020', 'close_20251021', 'close_20251022', 'close_20251023', 'close_20251024', 'close_20251027', 'close_20251028', 'close_20251029', 'close_20251030', 'close_20251031', 'close_20251103', 'close_20251104', 'close_20251105', 'close_20251106', 'close_20251107', 'close_20251110', 'close_20251111', 'close_20251112', 'close_20251113', 'close_20251114', 'volume_20251006', 'volume_20251007', 'volume_20251008', 'volume_20251009', 'volume_20251010', 'volume_20251013', 'volume_20251014', 'volume_20251015', 'volume_20251016', 'volume_20251017', 'volume_20251020', 'volume_20251021', 'volume_20251022', 'volume_20251023', 'volume_20251024', 'volume_20251027', 'volume_20251028', 'volume_20251029', 'volume_20251030', 'volume_20251031', 'volume_20251103', 'volume_20251104', 'volume_20251105', 'volume_20251106', 'volume_20251107', 'volume_20251110', 'volume_20251111', 'volume_20251112', 'volume_20251113', 'volume_20251114', 'vwap_20251006', 'vwap_20251007', 'vwap_20251008', 'vwap_20251009', 'vwap_20251010', 'vwap_20251013', 'vwap_20251014', 'vwap_20251015', 'vwap_20251016', 'vwap_20251017', 'vwap_20251020', 'vwap_20251021', 'vwap_20251022', 'vwap_20251023', 'vwap_20251024', 'vwap_20251027', 'vwap_20251028', 'vwap_20251029', 'vwap_20251030', 'vwap_20251031', 'vwap_20251103', 'vwap_20251104', 'vwap_20251105', 'vwap_20251106', 'vwap_20251107', 'vwap_20251110', 'vwap_20251111', 'vwap_20251112', 'vwap_20251113', 'vwap_20251114', 'rel_ret20251007', 'rel_ret20251008', 'rel_ret20251009', 'rel_ret20251010', 'rel_ret20251013', 'rel_ret20251014', 'rel_ret20251015', 'rel_ret20251016', 'rel_ret20251017', 'rel_ret20251020', 'rel_ret20251021', 'rel_ret20251022', 'rel_ret20251023', 'rel_ret20251024', 'rel_ret20251027', 'rel_ret20251028', 'rel_ret20251029', 'rel_ret20251030', 'rel_ret20251031', 'rel_ret20251103', 'rel_ret20251104', 'rel_ret20251105', 'rel_ret20251106', 'rel_ret20251107', 'rel_ret20251110', 'rel_ret20251111', 'rel_ret20251112', 'rel_ret20251113', 'rel_ret20251114', 'z_rel_ret20251007', 'z_rel_ret20251008', 'z_rel_ret20251009', 'z_rel_ret20251010', 'z_rel_ret20251013', 'z_rel_ret20251014', 'z_rel_ret20251015', 'z_rel_ret20251016', 'z_rel_ret20251017', 'z_rel_ret20251020', 'z_rel_ret20251021', 'z_rel_ret20251022', 'z_rel_ret20251023', 'z_rel_ret20251024', 'z_rel_ret20251027', 'z_rel_ret20251028', 'z_rel_ret20251029', 'z_rel_ret20251030', 'z_rel_ret20251031', 'z_rel_ret20251103', 'z_rel_ret20251104', 'z_rel_ret20251105', 'z_rel_ret20251106', 'z_rel_ret20251107', 'z_rel_ret20251110', 'z_rel_ret20251111', 'z_rel_ret20251112', 'z_rel_ret20251113', 'z_rel_ret20251114', 'label', 'pos_in_52w', 'dist_ma50', 'dist_ma200', 'ma_cross', 'log_mcap', 'float_to_out']\n"
     ]
    }
   ],
   "source": [
    "# now add the new label and clean the dataframe by dropping low value columns\n",
    "\n",
    "def clean_data(df):\n",
    "    df_clean = df.copy()\n",
    "    # remove columns that have no value for analysis, have large amount of\n",
    "    # missing data\n",
    "    drop_cols = ['companyOfficers', 'website', 'phone', 'irWebsite',\n",
    "                 'longBusinessSummary', 'address1', 'tradeable', 'quoteType',\n",
    "                 'language', 'region', 'quoteSourceName', 'triggerable', \n",
    "                 'customPriceAlertConfidence', 'marketState',\n",
    "                 'exchangeDataDelayedBy', 'sourceInterval', 'cryptoTradeable',\n",
    "                 'shortName', 'longName', 'hasPrePostMarketData',\n",
    "                 'corporateActions', 'messageBoardId', 'exchangeTimezoneName',\n",
    "                 'exchangeTimezoneShortName', 'gmtOffSetMilliseconds', 'fax',\n",
    "                 'market', 'esgPopulated', 'address2', 'displayName',\n",
    "                 'ipoExpectedDate', 'prevName', 'nameChangeDate',\n",
    "                 'industrySymbol', 'trailingPegRatio', 'lastSplitDate', \n",
    "                 'lastSplitFactor']\n",
    "\n",
    "    df_clean.drop(drop_cols, inplace=True, axis=1)\n",
    "    return df_clean\n",
    "\n",
    "df_cleaned = clean_data(df_with_label)\n",
    "# show label column\n",
    "print(df_cleaned['label'].head(20))\n",
    "# show all columns\n",
    "print(df_cleaned.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cf0769",
   "metadata": {},
   "source": [
    "Make adjustments to feature processing to keep time series columns separate from this first pipeline and not run it through a column transformer to leave the data. Need to make the time series data go in as a multi cahnel input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50307f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the time series columns we care about\n",
    "prefix_groups = {\n",
    "    \"open\": \"open_\",\n",
    "    \"close\": \"close_\",\n",
    "    \"high\": \"high_\",\n",
    "    \"low\": \"low_\",\n",
    "    \"volume\": \"volume_\",\n",
    "    \"vwap\": \"vwap_\",\n",
    "    \"rel_ret\": \"rel_ret\",\n",
    "    \"z_rel_ret\": \"z_rel_ret\"\n",
    "}\n",
    "ts_cols_by_group = {}\n",
    "for name, pref in prefix_groups.items():\n",
    "    cols = [c for c in df_cleaned.columns if c.startswith(pref)]\n",
    "    # sort by date suffix so time axis is ordered\n",
    "    cols = sorted(cols, key=lambda c: c.split('_')[-1])\n",
    "    ts_cols_by_group[name] = cols\n",
    "\n",
    "# trim timesetp to the minimum timestep in the groups\n",
    "min_timesteps = min(len(cols) for cols in ts_cols_by_group.values())\n",
    "for name, cols in ts_cols_by_group.items():\n",
    "    ts_cols_by_group[name] = cols[-min_timesteps:]\n",
    "\n",
    "# flatten all time-series columns into a list to drop them\n",
    "ts_all_cols = [c for cols in ts_cols_by_group.values() for c in cols]\n",
    "\n",
    "target = df_cleaned['label']\n",
    "# static features are everything except label, symbol, and all time-series\n",
    "static_features = df_cleaned.drop(columns=['label', 'symbol'] + ts_all_cols)\n",
    "\n",
    "X_train_static, X_test_static, y_train, y_test = train_test_split(\n",
    "    static_features,\n",
    "    target,\n",
    "    test_size=0.2,\n",
    "    random_state=44)\n",
    "\n",
    "# convert target labels to numpy array\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "\n",
    "# PROCESS THE STATIC FEATURES FIRST\n",
    "\n",
    "# identify all numerical and categorical columns in the static train df\n",
    "num_features = X_train_static.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_features = X_train_static.select_dtypes(include=['object']).columns\n",
    "\n",
    "# define a pipeline for numerical imputing and min max scaling\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', MinMaxScaler())])  # scale numerical features so no neg values\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# define processor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, num_features),\n",
    "        ('cat', cat_pipeline, cat_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# fit only on train to avoid data leakage\n",
    "X_train_static_proc = preprocessor.fit_transform(X_train_static).toarray()\n",
    "\n",
    "# use only transform on test data to prevent data leakage\n",
    "X_test_static_proc = preprocessor.transform(X_test_static).toarray()\n",
    "\n",
    "\n",
    "# Now we can process the multi-channel time-series input for Conv1D\n",
    "# get the same indices that we split on before\n",
    "train_idx = X_train_static.index\n",
    "test_idx = X_test_static.index\n",
    "\n",
    "def make_ts_block(cols, train_idx, test_idx):\n",
    "    # extract, scale, and return time series block for prefix\n",
    "    X_train_block = df_cleaned.loc[train_idx, cols]\n",
    "    X_test_block = df_cleaned.loc[test_idx, cols]\n",
    "    \n",
    "    # use standard scaler for time series blocks\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_block)\n",
    "    X_test_scaled = scaler.transform(X_test_block)\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "ts_train_blocks = []\n",
    "ts_test_blocks = []\n",
    "scalers_ts = {}\n",
    "\n",
    "for name, cols in ts_cols_by_group.items():\n",
    "    # get the train, test, and scaler for the block\n",
    "    X_tr_block, X_te_block, scaler = make_ts_block(cols, train_idx, test_idx)\n",
    "    scalers_ts[name] = scaler\n",
    "    ts_train_blocks.append(X_tr_block)\n",
    "    ts_test_blocks.append(X_te_block)\n",
    "\n",
    "# get the timesteps for the groups\n",
    "n_timesteps = ts_train_blocks[0].shape[1]\n",
    "n_train = ts_train_blocks[0].shape[0]\n",
    "n_test = ts_test_blocks[0].shape[0]\n",
    "n_channels = len(ts_train_blocks)\n",
    "\n",
    "# reshape each block to (batch, timesteps, 1) and stack as channels\n",
    "train_channels = [block.reshape(n_train, n_timesteps, 1) for block in ts_train_blocks]\n",
    "test_channels = [block.reshape(n_test, n_timesteps, 1) for block in ts_test_blocks]\n",
    "\n",
    "X_train_ts = np.concatenate(train_channels, axis=2)\n",
    "X_test_ts = np.concatenate(test_channels, axis=2)\n",
    "\n",
    "# model can now take dual input for static and timeseries input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d9ad9d",
   "metadata": {},
   "source": [
    "Now that we have two inputs, one for timeseries data and one for static data we can begin creating our convoluted neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7646c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 20:04:50.247257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 - 4s - 195ms/step - acc: 0.3583 - loss: 1.1566 - prec_neutral: 0.6757 - prec_over: 1.0000 - prec_under: 0.9545 - rec_neutral: 0.0279 - rec_over: 0.0662 - rec_under: 0.0252 - top2_acc: 0.6750 - val_acc: 0.3887 - val_loss: 1.1005 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7409\n",
      "Epoch 2/30\n",
      "19/19 - 1s - 35ms/step - acc: 0.4867 - loss: 1.0485 - prec_neutral: 0.7945 - prec_over: 0.8000 - prec_under: 0.8673 - rec_neutral: 0.0604 - rec_over: 0.0266 - rec_under: 0.0843 - top2_acc: 0.7892 - val_acc: 0.4551 - val_loss: 1.0742 - val_prec_neutral: 0.8000 - val_prec_over: 0.5833 - val_prec_under: 0.3333 - val_rec_neutral: 0.0231 - val_rec_over: 0.0809 - val_rec_under: 0.0058 - val_top2_acc: 0.7608\n",
      "Epoch 3/30\n",
      "19/19 - 1s - 36ms/step - acc: 0.5625 - loss: 0.9644 - prec_neutral: 0.6400 - prec_over: 0.6779 - prec_under: 0.7258 - rec_neutral: 0.1154 - rec_over: 0.1315 - rec_under: 0.1082 - top2_acc: 0.8517 - val_acc: 0.4850 - val_loss: 1.0476 - val_prec_neutral: 0.4688 - val_prec_over: 0.5909 - val_prec_under: 0.6250 - val_rec_neutral: 0.0867 - val_rec_over: 0.0751 - val_rec_under: 0.1156 - val_top2_acc: 0.7641\n",
      "Epoch 4/30\n",
      "19/19 - 1s - 32ms/step - acc: 0.6633 - loss: 0.8352 - prec_neutral: 0.4154 - prec_over: 0.5665 - prec_under: 0.8860 - rec_neutral: 0.1582 - rec_over: 0.1303 - rec_under: 0.2248 - top2_acc: 0.9050 - val_acc: 0.4850 - val_loss: 1.0389 - val_prec_neutral: 0.5323 - val_prec_over: 0.6111 - val_prec_under: 0.6081 - val_rec_neutral: 0.1908 - val_rec_over: 0.0636 - val_rec_under: 0.2601 - val_top2_acc: 0.8073\n",
      "Epoch 5/30\n",
      "19/19 - 1s - 33ms/step - acc: 0.7592 - loss: 0.6894 - prec_neutral: 0.6221 - prec_over: 0.9689 - prec_under: 0.7403 - rec_neutral: 0.2473 - rec_over: 0.2192 - rec_under: 0.2415 - top2_acc: 0.9417 - val_acc: 0.4850 - val_loss: 1.0259 - val_prec_neutral: 0.5524 - val_prec_over: 0.6296 - val_prec_under: 0.6200 - val_rec_neutral: 0.3353 - val_rec_over: 0.1965 - val_rec_under: 0.1792 - val_top2_acc: 0.8106\n",
      "Epoch 6/30\n",
      "19/19 - 1s - 32ms/step - acc: 0.8467 - loss: 0.5306 - prec_neutral: 0.7411 - prec_over: 0.6161 - prec_under: 0.4677 - rec_neutral: 0.2426 - rec_over: 0.2646 - rec_under: 0.2788 - top2_acc: 0.9717 - val_acc: 0.5216 - val_loss: 1.0091 - val_prec_neutral: 0.5068 - val_prec_over: 0.6056 - val_prec_under: 0.6250 - val_rec_neutral: 0.2139 - val_rec_over: 0.2486 - val_rec_under: 0.2601 - val_top2_acc: 0.8272\n",
      "Epoch 7/30\n",
      "19/19 - 1s - 32ms/step - acc: 0.8875 - loss: 0.4074 - prec_neutral: 0.6541 - prec_over: 0.5526 - prec_under: 0.7011 - rec_neutral: 0.2930 - rec_over: 0.2980 - rec_under: 0.3248 - top2_acc: 0.9833 - val_acc: 0.5116 - val_loss: 1.0403 - val_prec_neutral: 0.5000 - val_prec_over: 0.6000 - val_prec_under: 0.6395 - val_rec_neutral: 0.1965 - val_rec_over: 0.2601 - val_rec_under: 0.3179 - val_top2_acc: 0.8106\n",
      "Epoch 8/30\n",
      "19/19 - 1s - 32ms/step - acc: 0.9442 - loss: 0.2827 - prec_neutral: 0.6503 - prec_over: 0.9243 - prec_under: 0.6693 - rec_neutral: 0.3268 - rec_over: 0.3302 - rec_under: 0.3174 - top2_acc: 0.9908 - val_acc: 0.5050 - val_loss: 1.0735 - val_prec_neutral: 0.5172 - val_prec_over: 0.5824 - val_prec_under: 0.6264 - val_rec_neutral: 0.1734 - val_rec_over: 0.3064 - val_rec_under: 0.3295 - val_top2_acc: 0.8272\n",
      "Epoch 9/30\n",
      "19/19 - 1s - 32ms/step - acc: 0.9783 - loss: 0.1895 - prec_neutral: 0.7959 - prec_over: 0.7632 - prec_under: 0.8122 - rec_neutral: 0.3263 - rec_over: 0.3443 - rec_under: 0.3175 - top2_acc: 0.9983 - val_acc: 0.5449 - val_loss: 1.1113 - val_prec_neutral: 0.5543 - val_prec_over: 0.5890 - val_prec_under: 0.6322 - val_rec_neutral: 0.2948 - val_rec_over: 0.2486 - val_rec_under: 0.3179 - val_top2_acc: 0.8339\n",
      "Epoch 10/30\n",
      "19/19 - 1s - 32ms/step - acc: 0.9925 - loss: 0.1317 - prec_neutral: 0.6837 - prec_over: 0.5628 - prec_under: 0.5625 - rec_neutral: 0.3221 - rec_over: 0.3256 - rec_under: 0.3270 - top2_acc: 0.9983 - val_acc: 0.5382 - val_loss: 1.1399 - val_prec_neutral: 0.5444 - val_prec_over: 0.5699 - val_prec_under: 0.6479 - val_rec_neutral: 0.2832 - val_rec_over: 0.3064 - val_rec_under: 0.2659 - val_top2_acc: 0.8339\n",
      "Epoch 11/30\n",
      "19/19 - 1s - 32ms/step - acc: 0.9975 - loss: 0.0997 - prec_neutral: 0.6496 - prec_over: 0.7277 - prec_under: 0.5789 - rec_neutral: 0.3378 - rec_over: 0.3341 - rec_under: 0.3072 - top2_acc: 0.9992 - val_acc: 0.5216 - val_loss: 1.2158 - val_prec_neutral: 0.5682 - val_prec_over: 0.5942 - val_prec_under: 0.5963 - val_rec_neutral: 0.2890 - val_rec_over: 0.2370 - val_rec_under: 0.3757 - val_top2_acc: 0.8405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "layers = tf.keras.layers\n",
    "metrics = tf.keras.metrics\n",
    "\n",
    "# get the number of timesteps, channels, and static feature\n",
    "n_timesteps = X_train_ts.shape[1]\n",
    "n_channels = X_train_ts.shape[2]\n",
    "n_static = X_train_static_proc.shape[1]\n",
    "\n",
    "# add class weights\n",
    "classes = np.unique(y_train)   # should be [0, 1, 2]\n",
    "class_weights_arr = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weight = dict(zip(classes, class_weights_arr))\n",
    "\n",
    "# time series branch\n",
    "ts_input = tf.keras.Input(shape=(n_timesteps, n_channels), name=\"ts_input\")\n",
    "\n",
    "# define the time series branch of the convoluted NN\n",
    "# follow similar structure as the neural network trained in part 1\n",
    "# train static branch\n",
    "ts_branch = layers.Conv1D(filters=32, kernel_size=5, activation='relu', padding='causal')(ts_input)\n",
    "ts_branch = layers.MaxPooling1D(pool_size=2)(ts_branch)\n",
    "ts_branch = layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='causal')(ts_branch)\n",
    "ts_branch = layers.Dropout(0.1)(ts_branch)\n",
    "ts_branch = layers.GlobalAveragePooling1D()(ts_branch)\n",
    "\n",
    "# now train static branch\n",
    "static_input = tf.keras.Input(shape=(n_static,))\n",
    "static_branch = layers.Dense(256, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(1e-4))(static_input)\n",
    "static_branch = layers.Dropout(0.2)(static_branch)\n",
    "# merge branches\n",
    "merged = layers.Concatenate()([ts_branch, static_branch])\n",
    "# add dense layer after merging\n",
    "merged = layers.Dense(128, activation='relu')(merged)\n",
    "merged = layers.Dropout(0.3)(merged)\n",
    "output = layers.Dense(3, activation='softmax', name='prediction')(merged)\n",
    "\n",
    "\n",
    "model_conv_ts_static = tf.keras.models.Model(\n",
    "    inputs=[ts_input, static_input],\n",
    "    outputs=output,\n",
    "    name=\"conv1d_ts_plus_static_classifier\"\n",
    ")\n",
    "\n",
    "\n",
    "top2_acc_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=2,\n",
    "    name=\"top2_accuracy\"\n",
    ")\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model_conv_ts_static.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        metrics.SparseTopKCategoricalAccuracy(k=2, name='top2_acc'),\n",
    "        metrics.Precision(name='prec_under', class_id=0),\n",
    "        metrics.Recall(name='rec_under', class_id=0),\n",
    "        metrics.Precision(name='prec_neutral', class_id=1),\n",
    "        metrics.Recall(name='rec_neutral', class_id=1),\n",
    "        metrics.Precision(name='prec_over', class_id=2),\n",
    "        metrics.Recall(name='rec_over', class_id=2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# train model\n",
    "history = model_conv_ts_static.fit(\n",
    "    [X_train_ts, X_train_static_proc],  # both inputs\n",
    "    y_train,\n",
    "    validation_data=([X_test_ts, X_test_static_proc], y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b6176a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 45ms/step - acc: 0.5382 - loss: 1.0034 - prec_neutral: 0.7742 - prec_over: 0.6437 - prec_under: 0.8400 - rec_neutral: 0.1171 - rec_over: 0.2917 - rec_under: 0.3544 - top2_acc: 0.8173\n",
      "loss: 1.0034\n",
      "compile_metrics: 0.5382\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "Macro F1: 0.5196\n",
      "Weighted F1: 0.5155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       under       0.54      0.75      0.63        93\n",
      "     neutral       0.43      0.25      0.32       104\n",
      "        over       0.59      0.63      0.61       104\n",
      "\n",
      "    accuracy                           0.54       301\n",
      "   macro avg       0.52      0.55      0.52       301\n",
      "weighted avg       0.52      0.54      0.52       301\n",
      "\n",
      "[[70 13 10]\n",
      " [42 26 36]\n",
      " [17 21 66]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keras metrics\n",
    "results = model_conv_ts_static.evaluate(\n",
    "    [X_test_ts, X_test_static_proc],\n",
    "    y_test,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "for name, value in zip(model_conv_ts_static.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Predictions for sklearn metrics\n",
    "probs = model_conv_ts_static.predict([X_test_ts, X_test_static_proc])\n",
    "pred = probs.argmax(axis=1)\n",
    "\n",
    "macro_f1 = f1_score(y_test, pred, average='macro')\n",
    "weighted_f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pred,\n",
    "    target_names=['under', 'neutral', 'over']\n",
    "))\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "pd.DataFrame(history.history)[['loss', 'val_loss', 'acc', 'val_acc']].plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f1b68",
   "metadata": {},
   "source": [
    "Model is massively overfitting so we will make adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5289e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/19 - 8s - 408ms/step - acc: 0.4175 - loss: 1.1596 - prec_neutral: 0.7160 - prec_over: 0.6419 - prec_under: 0.5985 - rec_neutral: 0.2212 - rec_over: 0.2088 - rec_under: 0.2061 - top2_acc: 0.7492 - val_acc: 0.4186 - val_loss: 1.0880 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7575\n",
      "Epoch 2/30\n",
      "19/19 - 1s - 61ms/step - acc: 0.6217 - loss: 0.8698 - prec_neutral: 0.6545 - prec_over: 0.5816 - prec_under: 0.6194 - rec_neutral: 0.2163 - rec_over: 0.2429 - rec_under: 0.2553 - top2_acc: 0.8708 - val_acc: 0.4319 - val_loss: 1.0712 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.4286 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0173 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7708\n",
      "Epoch 3/30\n",
      "19/19 - 1s - 52ms/step - acc: 0.7108 - loss: 0.7195 - prec_neutral: 0.6678 - prec_over: 0.5799 - prec_under: 0.6176 - rec_neutral: 0.2296 - rec_over: 0.2784 - rec_under: 0.2899 - top2_acc: 0.9317 - val_acc: 0.4153 - val_loss: 1.0618 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.6000 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0867 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7641\n",
      "Epoch 4/30\n",
      "19/19 - 1s - 53ms/step - acc: 0.7933 - loss: 0.5664 - prec_neutral: 0.6688 - prec_over: 0.5793 - prec_under: 0.6183 - rec_neutral: 0.2500 - rec_over: 0.2855 - rec_under: 0.3059 - top2_acc: 0.9533 - val_acc: 0.4585 - val_loss: 1.0430 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5833 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.1214 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7774\n",
      "Epoch 5/30\n",
      "19/19 - 1s - 51ms/step - acc: 0.8300 - loss: 0.4688 - prec_neutral: 0.6638 - prec_over: 0.5903 - prec_under: 0.6119 - rec_neutral: 0.2752 - rec_over: 0.3111 - rec_under: 0.3019 - top2_acc: 0.9683 - val_acc: 0.4850 - val_loss: 1.0271 - val_prec_neutral: 0.5000 - val_prec_over: 0.6200 - val_prec_under: 0.5000 - val_rec_neutral: 0.0116 - val_rec_over: 0.1792 - val_rec_under: 0.0289 - val_top2_acc: 0.7874\n",
      "Epoch 6/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.8933 - loss: 0.3536 - prec_neutral: 0.6767 - prec_over: 0.6016 - prec_under: 0.6195 - rec_neutral: 0.2969 - rec_over: 0.3281 - rec_under: 0.3205 - top2_acc: 0.9842 - val_acc: 0.5150 - val_loss: 1.0114 - val_prec_neutral: 0.6667 - val_prec_over: 0.5818 - val_prec_under: 0.5882 - val_rec_neutral: 0.0347 - val_rec_over: 0.1850 - val_rec_under: 0.0578 - val_top2_acc: 0.7973\n",
      "Epoch 7/30\n",
      "19/19 - 1s - 51ms/step - acc: 0.9367 - loss: 0.2622 - prec_neutral: 0.6966 - prec_over: 0.5881 - prec_under: 0.6301 - rec_neutral: 0.3173 - rec_over: 0.3224 - rec_under: 0.3285 - top2_acc: 0.9900 - val_acc: 0.5017 - val_loss: 1.0020 - val_prec_neutral: 0.7500 - val_prec_over: 0.5909 - val_prec_under: 0.5000 - val_rec_neutral: 0.0520 - val_rec_over: 0.3006 - val_rec_under: 0.0578 - val_top2_acc: 0.7940\n",
      "Epoch 8/30\n",
      "19/19 - 1s - 56ms/step - acc: 0.9550 - loss: 0.2115 - prec_neutral: 0.7000 - prec_over: 0.5980 - prec_under: 0.6345 - rec_neutral: 0.3197 - rec_over: 0.3423 - rec_under: 0.3324 - top2_acc: 0.9933 - val_acc: 0.5482 - val_loss: 0.9906 - val_prec_neutral: 0.5600 - val_prec_over: 0.5890 - val_prec_under: 0.5000 - val_rec_neutral: 0.0809 - val_rec_over: 0.2486 - val_rec_under: 0.1214 - val_top2_acc: 0.8073\n",
      "Epoch 9/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.9625 - loss: 0.1673 - prec_neutral: 0.6955 - prec_over: 0.5985 - prec_under: 0.6288 - rec_neutral: 0.3185 - rec_over: 0.3409 - rec_under: 0.3311 - top2_acc: 0.9942 - val_acc: 0.5449 - val_loss: 0.9969 - val_prec_neutral: 0.6296 - val_prec_over: 0.6304 - val_prec_under: 0.5435 - val_rec_neutral: 0.0983 - val_rec_over: 0.3353 - val_rec_under: 0.1445 - val_top2_acc: 0.8040\n",
      "Epoch 10/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.9750 - loss: 0.1253 - prec_neutral: 0.6846 - prec_over: 0.5960 - prec_under: 0.6322 - rec_neutral: 0.3209 - rec_over: 0.3395 - rec_under: 0.3338 - top2_acc: 0.9958 - val_acc: 0.5349 - val_loss: 1.0018 - val_prec_neutral: 0.5128 - val_prec_over: 0.6250 - val_prec_under: 0.5208 - val_rec_neutral: 0.1156 - val_rec_over: 0.3468 - val_rec_under: 0.1445 - val_top2_acc: 0.8040\n",
      "Epoch 11/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.9925 - loss: 0.0945 - prec_neutral: 0.6921 - prec_over: 0.6000 - prec_under: 0.6300 - rec_neutral: 0.3269 - rec_over: 0.3452 - rec_under: 0.3351 - top2_acc: 0.9992 - val_acc: 0.5316 - val_loss: 1.0111 - val_prec_neutral: 0.5128 - val_prec_over: 0.5960 - val_prec_under: 0.5357 - val_rec_neutral: 0.1156 - val_rec_over: 0.3410 - val_rec_under: 0.1734 - val_top2_acc: 0.8073\n",
      "Epoch 12/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.9867 - loss: 0.0890 - prec_neutral: 0.6911 - prec_over: 0.6000 - prec_under: 0.6256 - rec_neutral: 0.3281 - rec_over: 0.3452 - rec_under: 0.3311 - top2_acc: 0.9992 - val_acc: 0.5482 - val_loss: 1.0468 - val_prec_neutral: 0.5526 - val_prec_over: 0.6204 - val_prec_under: 0.5556 - val_rec_neutral: 0.1214 - val_rec_over: 0.3873 - val_rec_under: 0.2312 - val_top2_acc: 0.7973\n",
      "Epoch 13/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.9967 - loss: 0.0709 - prec_neutral: 0.6889 - prec_over: 0.5961 - prec_under: 0.6303 - rec_neutral: 0.3221 - rec_over: 0.3438 - rec_under: 0.3378 - top2_acc: 1.0000 - val_acc: 0.5316 - val_loss: 1.0513 - val_prec_neutral: 0.5714 - val_prec_over: 0.6250 - val_prec_under: 0.5645 - val_rec_neutral: 0.2312 - val_rec_over: 0.3468 - val_rec_under: 0.2023 - val_top2_acc: 0.8173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "layers = tf.keras.layers\n",
    "metrics = tf.keras.metrics\n",
    "\n",
    "# get the number of timesteps, channels, and static feature\n",
    "n_timesteps = X_train_ts.shape[1]\n",
    "n_channels = X_train_ts.shape[2]\n",
    "n_static = X_train_static_proc.shape[1]\n",
    "\n",
    "# add class weights\n",
    "classes = np.unique(y_train)   # should be [0, 1, 2]\n",
    "class_weights_arr = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=classes,\n",
    "    y=y_train\n",
    ")\n",
    "class_weight = dict(zip(classes, class_weights_arr))\n",
    "\n",
    "# time series branch\n",
    "ts_input = tf.keras.Input(shape=(n_timesteps, n_channels), name=\"ts_input\")\n",
    "\n",
    "# define the time series branch of the convoluted NN\n",
    "# follow similar structure as the neural network trained in part 1\n",
    "# train static branch\n",
    "# add batch normalization to ts branch and remove max pooling\n",
    "ts_branch = layers.Conv1D(filters=16, kernel_size=3, activation='relu', padding='causal')(ts_input)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.Conv1D(filters=16, kernel_size=3, activation='relu', padding='causal')(ts_branch)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.GlobalAveragePooling1D()(ts_branch)\n",
    "ts_branch = layers.Dropout(0.1)(ts_branch)\n",
    "\n",
    "# now train static branch\n",
    "static_input = tf.keras.Input(shape=(n_static,))\n",
    "# added batch normalization inside raw static input\n",
    "static_branch = layers.BatchNormalization()(static_input)\n",
    "# reduced dense layer neurons to 128\n",
    "static_branch = layers.Dense(128, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(1e-4))(static_branch)\n",
    "static_branch = layers.Dropout(0.2)(static_branch)\n",
    "# merge branches\n",
    "merged = layers.Concatenate()([ts_branch, static_branch])\n",
    "# add dense layer after merging\n",
    "merged = layers.Dense(128, activation='relu')(merged)\n",
    "merged = layers.Dropout(0.3)(merged)\n",
    "output = layers.Dense(3, activation='softmax', name='prediction')(merged)\n",
    "\n",
    "\n",
    "model_conv_ts_static = tf.keras.models.Model(\n",
    "    inputs=[ts_input, static_input],\n",
    "    outputs=output,\n",
    "    name=\"conv1d_ts_plus_static_classifier\"\n",
    ")\n",
    "\n",
    "\n",
    "top2_acc_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=2,\n",
    "    name=\"top2_accuracy\"\n",
    ")\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model_conv_ts_static.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        metrics.SparseTopKCategoricalAccuracy(k=2, name='top2_acc'),\n",
    "        metrics.Precision(name='prec_under', class_id=0),\n",
    "        metrics.Recall(name='rec_under', class_id=0),\n",
    "        metrics.Precision(name='prec_neutral', class_id=1),\n",
    "        metrics.Recall(name='rec_neutral', class_id=1),\n",
    "        metrics.Precision(name='prec_over', class_id=2),\n",
    "        metrics.Recall(name='rec_over', class_id=2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# train model\n",
    "history = model_conv_ts_static.fit(\n",
    "    [X_train_ts, X_train_static_proc],  # both inputs\n",
    "    y_train,\n",
    "    validation_data=([X_test_ts, X_test_static_proc], y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight,\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "053a8899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - 89ms/step - acc: 0.5482 - loss: 0.9906 - prec_neutral: 0.6400 - prec_over: 0.6712 - prec_under: 0.7143 - rec_neutral: 0.0780 - rec_over: 0.2552 - rec_under: 0.1266 - top2_acc: 0.8073\n",
      "loss: 0.9906\n",
      "compile_metrics: 0.5482\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Macro F1: 0.5409\n",
      "Weighted F1: 0.5390\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       under       0.63      0.56      0.59        93\n",
      "     neutral       0.45      0.36      0.40       104\n",
      "        over       0.55      0.73      0.63       104\n",
      "\n",
      "    accuracy                           0.55       301\n",
      "   macro avg       0.55      0.55      0.54       301\n",
      "weighted avg       0.54      0.55      0.54       301\n",
      "\n",
      "[[52 22 19]\n",
      " [25 37 42]\n",
      " [ 5 23 76]]\n"
     ]
    }
   ],
   "source": [
    "# Keras metrics\n",
    "results = model_conv_ts_static.evaluate(\n",
    "    [X_test_ts, X_test_static_proc],\n",
    "    y_test,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "for name, value in zip(model_conv_ts_static.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Predictions for sklearn metrics\n",
    "probs = model_conv_ts_static.predict([X_test_ts, X_test_static_proc])\n",
    "pred = probs.argmax(axis=1)\n",
    "\n",
    "macro_f1 = f1_score(y_test, pred, average='macro')\n",
    "weighted_f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pred,\n",
    "    target_names=['under', 'neutral', 'over']\n",
    "))\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea328d3f",
   "metadata": {},
   "source": [
    "Performance slightly improved but model is still massively overfitting, add more regularization to every dense and conv1d layer and lower learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7b1fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/19 - 7s - 377ms/step - acc: 0.3525 - loss: 1.3231 - prec_neutral: 0.7100 - prec_over: 0.6171 - prec_under: 0.6434 - rec_neutral: 0.1971 - rec_over: 0.2358 - rec_under: 0.2088 - top2_acc: 0.6950 - val_acc: 0.3555 - val_loss: 1.1518 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.6412\n",
      "Epoch 2/30\n",
      "19/19 - 1s - 63ms/step - acc: 0.4192 - loss: 1.2037 - prec_neutral: 0.7207 - prec_over: 0.6078 - prec_under: 0.6104 - rec_neutral: 0.1923 - rec_over: 0.2443 - rec_under: 0.1875 - top2_acc: 0.7267 - val_acc: 0.3455 - val_loss: 1.1418 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.6744\n",
      "Epoch 3/30\n",
      "19/19 - 1s - 53ms/step - acc: 0.4542 - loss: 1.1460 - prec_neutral: 0.7224 - prec_over: 0.5956 - prec_under: 0.6151 - rec_neutral: 0.2127 - rec_over: 0.2301 - rec_under: 0.2061 - top2_acc: 0.7725 - val_acc: 0.3621 - val_loss: 1.1329 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.6744\n",
      "Epoch 4/30\n",
      "19/19 - 1s - 52ms/step - acc: 0.4908 - loss: 1.0716 - prec_neutral: 0.6886 - prec_over: 0.6434 - prec_under: 0.6420 - rec_neutral: 0.1887 - rec_over: 0.2486 - rec_under: 0.2194 - top2_acc: 0.7950 - val_acc: 0.3787 - val_loss: 1.1239 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.6667 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0116 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7176\n",
      "Epoch 5/30\n",
      "19/19 - 1s - 53ms/step - acc: 0.5342 - loss: 1.0042 - prec_neutral: 0.7382 - prec_over: 0.6027 - prec_under: 0.6400 - rec_neutral: 0.2067 - rec_over: 0.2543 - rec_under: 0.2128 - top2_acc: 0.8175 - val_acc: 0.3953 - val_loss: 1.1145 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5000 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0173 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7575\n",
      "Epoch 6/30\n",
      "19/19 - 1s - 53ms/step - acc: 0.5883 - loss: 0.9423 - prec_neutral: 0.6958 - prec_over: 0.5958 - prec_under: 0.6255 - rec_neutral: 0.2007 - rec_over: 0.2429 - rec_under: 0.2287 - top2_acc: 0.8542 - val_acc: 0.3987 - val_loss: 1.1049 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5714 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0231 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7807\n",
      "Epoch 7/30\n",
      "19/19 - 1s - 52ms/step - acc: 0.6008 - loss: 0.9221 - prec_neutral: 0.7049 - prec_over: 0.5788 - prec_under: 0.6212 - rec_neutral: 0.2067 - rec_over: 0.2401 - rec_under: 0.2420 - top2_acc: 0.8642 - val_acc: 0.4286 - val_loss: 1.0955 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5556 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0289 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7874\n",
      "Epoch 8/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.6208 - loss: 0.9021 - prec_neutral: 0.7073 - prec_over: 0.5818 - prec_under: 0.6074 - rec_neutral: 0.2091 - rec_over: 0.2628 - rec_under: 0.2407 - top2_acc: 0.8625 - val_acc: 0.4817 - val_loss: 1.0863 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.6000 - val_prec_under: 1.0000 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0347 - val_rec_under: 0.0058 - val_top2_acc: 0.7973\n",
      "Epoch 9/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.6508 - loss: 0.8281 - prec_neutral: 0.7237 - prec_over: 0.5784 - prec_under: 0.6287 - rec_neutral: 0.2236 - rec_over: 0.2514 - rec_under: 0.2566 - top2_acc: 0.8975 - val_acc: 0.4983 - val_loss: 1.0769 - val_prec_neutral: 1.0000 - val_prec_over: 0.5833 - val_prec_under: 1.0000 - val_rec_neutral: 0.0058 - val_rec_over: 0.0405 - val_rec_under: 0.0116 - val_top2_acc: 0.8173\n",
      "Epoch 10/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.6592 - loss: 0.8232 - prec_neutral: 0.7309 - prec_over: 0.6084 - prec_under: 0.6528 - rec_neutral: 0.2188 - rec_over: 0.2670 - rec_under: 0.2926 - top2_acc: 0.9058 - val_acc: 0.5050 - val_loss: 1.0667 - val_prec_neutral: 1.0000 - val_prec_over: 0.6000 - val_prec_under: 0.3750 - val_rec_neutral: 0.0116 - val_rec_over: 0.0520 - val_rec_under: 0.0173 - val_top2_acc: 0.8272\n",
      "Epoch 11/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.6925 - loss: 0.7736 - prec_neutral: 0.6701 - prec_over: 0.5994 - prec_under: 0.6231 - rec_neutral: 0.2320 - rec_over: 0.2699 - rec_under: 0.2793 - top2_acc: 0.9108 - val_acc: 0.4950 - val_loss: 1.0571 - val_prec_neutral: 1.0000 - val_prec_over: 0.6471 - val_prec_under: 0.4615 - val_rec_neutral: 0.0116 - val_rec_over: 0.0636 - val_rec_under: 0.0347 - val_top2_acc: 0.8206\n",
      "Epoch 12/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.6975 - loss: 0.7425 - prec_neutral: 0.7031 - prec_over: 0.5841 - prec_under: 0.6102 - rec_neutral: 0.2163 - rec_over: 0.2713 - rec_under: 0.2872 - top2_acc: 0.9058 - val_acc: 0.5083 - val_loss: 1.0479 - val_prec_neutral: 1.0000 - val_prec_over: 0.6190 - val_prec_under: 0.5556 - val_rec_neutral: 0.0173 - val_rec_over: 0.0751 - val_rec_under: 0.0578 - val_top2_acc: 0.8272\n",
      "Epoch 13/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.7208 - loss: 0.7225 - prec_neutral: 0.7143 - prec_over: 0.5965 - prec_under: 0.6316 - rec_neutral: 0.2404 - rec_over: 0.2898 - rec_under: 0.2872 - top2_acc: 0.9167 - val_acc: 0.5150 - val_loss: 1.0378 - val_prec_neutral: 1.0000 - val_prec_over: 0.7037 - val_prec_under: 0.5769 - val_rec_neutral: 0.0231 - val_rec_over: 0.1098 - val_rec_under: 0.0867 - val_top2_acc: 0.8306\n",
      "Epoch 14/30\n",
      "19/19 - 1s - 54ms/step - acc: 0.7550 - loss: 0.6810 - prec_neutral: 0.6923 - prec_over: 0.5935 - prec_under: 0.6203 - rec_neutral: 0.2272 - rec_over: 0.2841 - rec_under: 0.2846 - top2_acc: 0.9350 - val_acc: 0.5249 - val_loss: 1.0289 - val_prec_neutral: 0.7778 - val_prec_over: 0.7037 - val_prec_under: 0.5789 - val_rec_neutral: 0.0405 - val_rec_over: 0.1098 - val_rec_under: 0.1272 - val_top2_acc: 0.8439\n",
      "Epoch 15/30\n",
      "19/19 - 1s - 65ms/step - acc: 0.7667 - loss: 0.6547 - prec_neutral: 0.6847 - prec_over: 0.6006 - prec_under: 0.6050 - rec_neutral: 0.2428 - rec_over: 0.2884 - rec_under: 0.2872 - top2_acc: 0.9425 - val_acc: 0.5249 - val_loss: 1.0220 - val_prec_neutral: 0.7143 - val_prec_over: 0.6786 - val_prec_under: 0.5682 - val_rec_neutral: 0.0578 - val_rec_over: 0.1098 - val_rec_under: 0.1445 - val_top2_acc: 0.8339\n",
      "Epoch 16/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.7717 - loss: 0.6249 - prec_neutral: 0.6701 - prec_over: 0.5714 - prec_under: 0.6069 - rec_neutral: 0.2320 - rec_over: 0.2841 - rec_under: 0.2793 - top2_acc: 0.9467 - val_acc: 0.5316 - val_loss: 1.0153 - val_prec_neutral: 0.5714 - val_prec_over: 0.6667 - val_prec_under: 0.5882 - val_rec_neutral: 0.0694 - val_rec_over: 0.1272 - val_rec_under: 0.1734 - val_top2_acc: 0.8372\n",
      "Epoch 17/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.7842 - loss: 0.6135 - prec_neutral: 0.7162 - prec_over: 0.5803 - prec_under: 0.6270 - rec_neutral: 0.2548 - rec_over: 0.2926 - rec_under: 0.3152 - top2_acc: 0.9433 - val_acc: 0.5349 - val_loss: 1.0094 - val_prec_neutral: 0.6207 - val_prec_over: 0.6154 - val_prec_under: 0.6000 - val_rec_neutral: 0.1040 - val_rec_over: 0.1387 - val_rec_under: 0.1908 - val_top2_acc: 0.8306\n",
      "Epoch 18/30\n",
      "19/19 - 1s - 53ms/step - acc: 0.7925 - loss: 0.6051 - prec_neutral: 0.6962 - prec_over: 0.5677 - prec_under: 0.6267 - rec_neutral: 0.2644 - rec_over: 0.2798 - rec_under: 0.3059 - top2_acc: 0.9492 - val_acc: 0.5382 - val_loss: 1.0063 - val_prec_neutral: 0.6000 - val_prec_over: 0.6000 - val_prec_under: 0.6406 - val_rec_neutral: 0.1214 - val_rec_over: 0.1561 - val_rec_under: 0.2370 - val_top2_acc: 0.8372\n",
      "Epoch 19/30\n",
      "19/19 - 1s - 52ms/step - acc: 0.8067 - loss: 0.5569 - prec_neutral: 0.7182 - prec_over: 0.6081 - prec_under: 0.6133 - rec_neutral: 0.2849 - rec_over: 0.2997 - rec_under: 0.3059 - top2_acc: 0.9608 - val_acc: 0.5415 - val_loss: 1.0055 - val_prec_neutral: 0.6216 - val_prec_over: 0.6071 - val_prec_under: 0.6269 - val_rec_neutral: 0.1329 - val_rec_over: 0.1965 - val_rec_under: 0.2428 - val_top2_acc: 0.8339\n",
      "Epoch 20/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.8217 - loss: 0.5455 - prec_neutral: 0.7045 - prec_over: 0.5642 - prec_under: 0.6505 - rec_neutral: 0.2837 - rec_over: 0.2869 - rec_under: 0.3218 - top2_acc: 0.9558 - val_acc: 0.5515 - val_loss: 1.0071 - val_prec_neutral: 0.6136 - val_prec_over: 0.6102 - val_prec_under: 0.6269 - val_rec_neutral: 0.1561 - val_rec_over: 0.2081 - val_rec_under: 0.2428 - val_top2_acc: 0.8339\n",
      "Epoch 21/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.8308 - loss: 0.5241 - prec_neutral: 0.6710 - prec_over: 0.5876 - prec_under: 0.6202 - rec_neutral: 0.2500 - rec_over: 0.3097 - rec_under: 0.3191 - top2_acc: 0.9642 - val_acc: 0.5449 - val_loss: 1.0099 - val_prec_neutral: 0.6038 - val_prec_over: 0.5806 - val_prec_under: 0.6286 - val_rec_neutral: 0.1850 - val_rec_over: 0.2081 - val_rec_under: 0.2543 - val_top2_acc: 0.8405\n",
      "Epoch 22/30\n",
      "19/19 - 1s - 52ms/step - acc: 0.8358 - loss: 0.4993 - prec_neutral: 0.7086 - prec_over: 0.5934 - prec_under: 0.6227 - rec_neutral: 0.2776 - rec_over: 0.3068 - rec_under: 0.3138 - top2_acc: 0.9692 - val_acc: 0.5482 - val_loss: 1.0146 - val_prec_neutral: 0.6034 - val_prec_over: 0.5882 - val_prec_under: 0.6301 - val_rec_neutral: 0.2023 - val_rec_over: 0.2312 - val_rec_under: 0.2659 - val_top2_acc: 0.8439\n",
      "Epoch 23/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.8300 - loss: 0.4919 - prec_neutral: 0.6901 - prec_over: 0.5934 - prec_under: 0.6105 - rec_neutral: 0.2596 - rec_over: 0.3068 - rec_under: 0.3085 - top2_acc: 0.9708 - val_acc: 0.5349 - val_loss: 1.0230 - val_prec_neutral: 0.5970 - val_prec_over: 0.5571 - val_prec_under: 0.6420 - val_rec_neutral: 0.2312 - val_rec_over: 0.2254 - val_rec_under: 0.3006 - val_top2_acc: 0.8505\n",
      "Epoch 24/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.8708 - loss: 0.4411 - prec_neutral: 0.6844 - prec_over: 0.6069 - prec_under: 0.6328 - rec_neutral: 0.2788 - rec_over: 0.3267 - rec_under: 0.3231 - top2_acc: 0.9775 - val_acc: 0.5382 - val_loss: 1.0338 - val_prec_neutral: 0.5857 - val_prec_over: 0.5507 - val_prec_under: 0.6250 - val_rec_neutral: 0.2370 - val_rec_over: 0.2197 - val_rec_under: 0.3179 - val_top2_acc: 0.8505\n"
     ]
    }
   ],
   "source": [
    "layers = tf.keras.layers\n",
    "metrics = tf.keras.metrics\n",
    "\n",
    "# get the number of timesteps, channels, and static feature\n",
    "n_timesteps = X_train_ts.shape[1]\n",
    "n_channels = X_train_ts.shape[2]\n",
    "n_static = X_train_static_proc.shape[1]\n",
    "\n",
    "\n",
    "# time series branch\n",
    "ts_input = tf.keras.Input(shape=(n_timesteps, n_channels), name=\"ts_input\")\n",
    "\n",
    "# define the time series branch of the convoluted NN\n",
    "# follow similar structure as the neural network trained in part 1\n",
    "# train static branch\n",
    "# add batch normalization to ts branch and remove max pooling\n",
    "ts_branch = layers.Conv1D(filters=32, kernel_size=5, activation='relu', padding='causal')(ts_input)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.Conv1D(filters=16, kernel_size=3, activation='relu', \n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-3), padding='causal')(ts_branch)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.GlobalAveragePooling1D()(ts_branch)\n",
    "ts_branch = layers.Dropout(0.1)(ts_branch)\n",
    "\n",
    "# now train static branch\n",
    "static_input = tf.keras.Input(shape=(n_static,))\n",
    "# added batch normalization inside raw static input\n",
    "static_branch = layers.BatchNormalization()(static_input)\n",
    "# reduced dense layer neurons to 128\n",
    "static_branch = layers.Dense(128, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(1e-4))(static_branch)\n",
    "static_branch = layers.Dropout(0.2)(static_branch)\n",
    "# merge branches\n",
    "merged = layers.Concatenate()([ts_branch, static_branch])\n",
    "# add dense layer after merging\n",
    "merged = layers.Dense(64, activation='relu')(merged)\n",
    "merged = layers.Dropout(0.3)(merged)\n",
    "output = layers.Dense(3, activation='softmax', name='prediction')(merged)\n",
    "\n",
    "\n",
    "model_conv_ts_static = tf.keras.models.Model(\n",
    "    inputs=[ts_input, static_input],\n",
    "    outputs=output,\n",
    "    name=\"conv1d_ts_plus_static_classifier\"\n",
    ")\n",
    "\n",
    "\n",
    "top2_acc_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=2,\n",
    "    name=\"top2_accuracy\"\n",
    ")\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model_conv_ts_static.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        metrics.SparseTopKCategoricalAccuracy(k=2, name='top2_acc'),\n",
    "        metrics.Precision(name='prec_under', class_id=0),\n",
    "        metrics.Recall(name='rec_under', class_id=0),\n",
    "        metrics.Precision(name='prec_neutral', class_id=1),\n",
    "        metrics.Recall(name='rec_neutral', class_id=1),\n",
    "        metrics.Precision(name='prec_over', class_id=2),\n",
    "        metrics.Recall(name='rec_over', class_id=2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# train model\n",
    "history = model_conv_ts_static.fit(\n",
    "    [X_train_ts, X_train_static_proc],  # both inputs\n",
    "    y_train,\n",
    "    validation_data=([X_test_ts, X_test_static_proc], y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0caee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - 86ms/step - acc: 0.5415 - loss: 1.0055 - prec_neutral: 0.7297 - prec_over: 0.6071 - prec_under: 0.8060 - rec_neutral: 0.1317 - rec_over: 0.1771 - rec_under: 0.2278 - top2_acc: 0.8339\n",
      "loss: 1.0055\n",
      "compile_metrics: 0.5415\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Macro F1: 0.5427\n",
      "Weighted F1: 0.5415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       under       0.54      0.61      0.58        93\n",
      "     neutral       0.44      0.42      0.43       104\n",
      "        over       0.65      0.60      0.62       104\n",
      "\n",
      "    accuracy                           0.54       301\n",
      "   macro avg       0.54      0.54      0.54       301\n",
      "weighted avg       0.54      0.54      0.54       301\n",
      "\n",
      "[[57 29  7]\n",
      " [34 44 26]\n",
      " [14 28 62]]\n"
     ]
    }
   ],
   "source": [
    "# Keras metrics\n",
    "results = model_conv_ts_static.evaluate(\n",
    "    [X_test_ts, X_test_static_proc],\n",
    "    y_test,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "for name, value in zip(model_conv_ts_static.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Predictions for sklearn metrics\n",
    "probs = model_conv_ts_static.predict([X_test_ts, X_test_static_proc])\n",
    "pred = probs.argmax(axis=1)\n",
    "\n",
    "macro_f1 = f1_score(y_test, pred, average='macro')\n",
    "weighted_f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pred,\n",
    "    target_names=['under', 'neutral', 'over']\n",
    "))\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e3b2f",
   "metadata": {},
   "source": [
    "Still overfitting, will try adding max pooling, and adjusting the layer sizes and dropout in time series branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7b922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/19 - 8s - 414ms/step - acc: 0.3408 - loss: 1.4399 - prec_neutral: 0.6779 - prec_over: 0.6047 - prec_under: 0.6293 - rec_neutral: 0.2175 - rec_over: 0.2216 - rec_under: 0.2168 - top2_acc: 0.6592 - val_acc: 0.3821 - val_loss: 1.1532 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7409\n",
      "Epoch 2/30\n",
      "19/19 - 2s - 80ms/step - acc: 0.4092 - loss: 1.2539 - prec_neutral: 0.6880 - prec_over: 0.6171 - prec_under: 0.5932 - rec_neutral: 0.2067 - rec_over: 0.2358 - rec_under: 0.2074 - top2_acc: 0.7442 - val_acc: 0.3854 - val_loss: 1.1420 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7375\n",
      "Epoch 3/30\n",
      "19/19 - 1s - 57ms/step - acc: 0.4533 - loss: 1.1936 - prec_neutral: 0.6721 - prec_over: 0.6107 - prec_under: 0.6336 - rec_neutral: 0.1995 - rec_over: 0.2585 - rec_under: 0.2207 - top2_acc: 0.7433 - val_acc: 0.4053 - val_loss: 1.1317 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7575\n",
      "Epoch 4/30\n",
      "19/19 - 1s - 54ms/step - acc: 0.4967 - loss: 1.0871 - prec_neutral: 0.7056 - prec_over: 0.5594 - prec_under: 0.5884 - rec_neutral: 0.1959 - rec_over: 0.2273 - rec_under: 0.2301 - top2_acc: 0.7967 - val_acc: 0.4319 - val_loss: 1.1213 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.3333 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0058 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7708\n",
      "Epoch 5/30\n",
      "19/19 - 1s - 53ms/step - acc: 0.5375 - loss: 1.0240 - prec_neutral: 0.7080 - prec_over: 0.5662 - prec_under: 0.6182 - rec_neutral: 0.1923 - rec_over: 0.2429 - rec_under: 0.2434 - top2_acc: 0.8217 - val_acc: 0.4684 - val_loss: 1.1103 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.2500 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0058 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7807\n",
      "Epoch 6/30\n",
      "19/19 - 1s - 67ms/step - acc: 0.5925 - loss: 0.9619 - prec_neutral: 0.7046 - prec_over: 0.6033 - prec_under: 0.6025 - rec_neutral: 0.2007 - rec_over: 0.2614 - rec_under: 0.2540 - top2_acc: 0.8467 - val_acc: 0.4950 - val_loss: 1.0991 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5000 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0231 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.8206\n",
      "Epoch 7/30\n",
      "19/19 - 1s - 56ms/step - acc: 0.6192 - loss: 0.9180 - prec_neutral: 0.7230 - prec_over: 0.5945 - prec_under: 0.6262 - rec_neutral: 0.1851 - rec_over: 0.2770 - rec_under: 0.2606 - top2_acc: 0.8667 - val_acc: 0.4983 - val_loss: 1.0870 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5000 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0231 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.8239\n",
      "Epoch 8/30\n",
      "19/19 - 1s - 57ms/step - acc: 0.6517 - loss: 0.8684 - prec_neutral: 0.6911 - prec_over: 0.5942 - prec_under: 0.5735 - rec_neutral: 0.2043 - rec_over: 0.2642 - rec_under: 0.2593 - top2_acc: 0.8867 - val_acc: 0.5183 - val_loss: 1.0758 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5000 - val_prec_under: 0.5000 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0289 - val_rec_under: 0.0058 - val_top2_acc: 0.8272\n",
      "Epoch 9/30\n",
      "19/19 - 1s - 51ms/step - acc: 0.6658 - loss: 0.8362 - prec_neutral: 0.6898 - prec_over: 0.5976 - prec_under: 0.5831 - rec_neutral: 0.2031 - rec_over: 0.2869 - rec_under: 0.2473 - top2_acc: 0.8967 - val_acc: 0.5216 - val_loss: 1.0639 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5625 - val_prec_under: 0.4286 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0520 - val_rec_under: 0.0173 - val_top2_acc: 0.8439\n",
      "Epoch 10/30\n",
      "19/19 - 1s - 53ms/step - acc: 0.6775 - loss: 0.8109 - prec_neutral: 0.6732 - prec_over: 0.6019 - prec_under: 0.5879 - rec_neutral: 0.2079 - rec_over: 0.2770 - rec_under: 0.2713 - top2_acc: 0.9083 - val_acc: 0.5249 - val_loss: 1.0520 - val_prec_neutral: 0.6000 - val_prec_over: 0.5556 - val_prec_under: 0.6000 - val_rec_neutral: 0.0173 - val_rec_over: 0.0578 - val_rec_under: 0.0347 - val_top2_acc: 0.8505\n",
      "Epoch 11/30\n",
      "19/19 - 1s - 68ms/step - acc: 0.7008 - loss: 0.7627 - prec_neutral: 0.6846 - prec_over: 0.5823 - prec_under: 0.6169 - rec_neutral: 0.2139 - rec_over: 0.2713 - rec_under: 0.2912 - top2_acc: 0.8992 - val_acc: 0.5216 - val_loss: 1.0406 - val_prec_neutral: 0.6250 - val_prec_over: 0.5909 - val_prec_under: 0.5000 - val_rec_neutral: 0.0289 - val_rec_over: 0.0751 - val_rec_under: 0.0347 - val_top2_acc: 0.8571\n",
      "Epoch 12/30\n",
      "19/19 - 1s - 52ms/step - acc: 0.7092 - loss: 0.7315 - prec_neutral: 0.6562 - prec_over: 0.5782 - prec_under: 0.6147 - rec_neutral: 0.2272 - rec_over: 0.2784 - rec_under: 0.2886 - top2_acc: 0.9367 - val_acc: 0.5249 - val_loss: 1.0292 - val_prec_neutral: 0.6667 - val_prec_over: 0.6000 - val_prec_under: 0.5625 - val_rec_neutral: 0.0462 - val_rec_over: 0.1040 - val_rec_under: 0.0520 - val_top2_acc: 0.8571\n",
      "Epoch 13/30\n",
      "19/19 - 1s - 73ms/step - acc: 0.7358 - loss: 0.7125 - prec_neutral: 0.6761 - prec_over: 0.5838 - prec_under: 0.6154 - rec_neutral: 0.2308 - rec_over: 0.2969 - rec_under: 0.2979 - top2_acc: 0.9342 - val_acc: 0.5382 - val_loss: 1.0188 - val_prec_neutral: 0.6923 - val_prec_over: 0.5946 - val_prec_under: 0.5455 - val_rec_neutral: 0.0520 - val_rec_over: 0.1272 - val_rec_under: 0.0694 - val_top2_acc: 0.8571\n",
      "Epoch 14/30\n",
      "19/19 - 1s - 69ms/step - acc: 0.7458 - loss: 0.6756 - prec_neutral: 0.6618 - prec_over: 0.5881 - prec_under: 0.6053 - rec_neutral: 0.2188 - rec_over: 0.2940 - rec_under: 0.3019 - top2_acc: 0.9425 - val_acc: 0.5449 - val_loss: 1.0080 - val_prec_neutral: 0.7500 - val_prec_over: 0.6136 - val_prec_under: 0.5517 - val_rec_neutral: 0.0694 - val_rec_over: 0.1561 - val_rec_under: 0.0925 - val_top2_acc: 0.8704\n",
      "Epoch 15/30\n",
      "19/19 - 1s - 61ms/step - acc: 0.7692 - loss: 0.6492 - prec_neutral: 0.6946 - prec_over: 0.5887 - prec_under: 0.6243 - rec_neutral: 0.2488 - rec_over: 0.3111 - rec_under: 0.3005 - top2_acc: 0.9433 - val_acc: 0.5382 - val_loss: 0.9981 - val_prec_neutral: 0.7083 - val_prec_over: 0.6327 - val_prec_under: 0.5789 - val_rec_neutral: 0.0983 - val_rec_over: 0.1792 - val_rec_under: 0.1272 - val_top2_acc: 0.8605\n",
      "Epoch 16/30\n",
      "19/19 - 1s - 53ms/step - acc: 0.7683 - loss: 0.6268 - prec_neutral: 0.6901 - prec_over: 0.5868 - prec_under: 0.6306 - rec_neutral: 0.2356 - rec_over: 0.3168 - rec_under: 0.3019 - top2_acc: 0.9550 - val_acc: 0.5415 - val_loss: 0.9891 - val_prec_neutral: 0.5938 - val_prec_over: 0.6481 - val_prec_under: 0.5682 - val_rec_neutral: 0.1098 - val_rec_over: 0.2023 - val_rec_under: 0.1445 - val_top2_acc: 0.8538\n",
      "Epoch 17/30\n",
      "19/19 - 1s - 52ms/step - acc: 0.7900 - loss: 0.5913 - prec_neutral: 0.6926 - prec_over: 0.5857 - prec_under: 0.6113 - rec_neutral: 0.2356 - rec_over: 0.2912 - rec_under: 0.3178 - top2_acc: 0.9542 - val_acc: 0.5482 - val_loss: 0.9819 - val_prec_neutral: 0.5610 - val_prec_over: 0.6441 - val_prec_under: 0.5918 - val_rec_neutral: 0.1329 - val_rec_over: 0.2197 - val_rec_under: 0.1676 - val_top2_acc: 0.8538\n",
      "Epoch 18/30\n",
      "19/19 - 1s - 51ms/step - acc: 0.8092 - loss: 0.5486 - prec_neutral: 0.6731 - prec_over: 0.5795 - prec_under: 0.6247 - rec_neutral: 0.2500 - rec_over: 0.3054 - rec_under: 0.3165 - top2_acc: 0.9658 - val_acc: 0.5515 - val_loss: 0.9764 - val_prec_neutral: 0.5111 - val_prec_over: 0.6500 - val_prec_under: 0.6379 - val_rec_neutral: 0.1329 - val_rec_over: 0.2254 - val_rec_under: 0.2139 - val_top2_acc: 0.8538\n",
      "Epoch 19/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.8117 - loss: 0.5513 - prec_neutral: 0.6942 - prec_over: 0.5770 - prec_under: 0.6016 - rec_neutral: 0.2728 - rec_over: 0.2926 - rec_under: 0.3072 - top2_acc: 0.9633 - val_acc: 0.5482 - val_loss: 0.9726 - val_prec_neutral: 0.5400 - val_prec_over: 0.6212 - val_prec_under: 0.6269 - val_rec_neutral: 0.1561 - val_rec_over: 0.2370 - val_rec_under: 0.2428 - val_top2_acc: 0.8571\n",
      "Epoch 20/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.8217 - loss: 0.5218 - prec_neutral: 0.7072 - prec_over: 0.5942 - prec_under: 0.6206 - rec_neutral: 0.2728 - rec_over: 0.3224 - rec_under: 0.3045 - top2_acc: 0.9667 - val_acc: 0.5515 - val_loss: 0.9694 - val_prec_neutral: 0.5556 - val_prec_over: 0.6324 - val_prec_under: 0.6269 - val_rec_neutral: 0.2023 - val_rec_over: 0.2486 - val_rec_under: 0.2428 - val_top2_acc: 0.8605\n",
      "Epoch 21/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.8475 - loss: 0.4846 - prec_neutral: 0.6799 - prec_over: 0.5801 - prec_under: 0.6194 - rec_neutral: 0.2680 - rec_over: 0.3139 - rec_under: 0.3138 - top2_acc: 0.9667 - val_acc: 0.5449 - val_loss: 0.9689 - val_prec_neutral: 0.5606 - val_prec_over: 0.6389 - val_prec_under: 0.6338 - val_rec_neutral: 0.2139 - val_rec_over: 0.2659 - val_rec_under: 0.2601 - val_top2_acc: 0.8605\n",
      "Epoch 22/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.8642 - loss: 0.4614 - prec_neutral: 0.6748 - prec_over: 0.6042 - prec_under: 0.6162 - rec_neutral: 0.2668 - rec_over: 0.3295 - rec_under: 0.3138 - top2_acc: 0.9750 - val_acc: 0.5515 - val_loss: 0.9734 - val_prec_neutral: 0.5676 - val_prec_over: 0.6301 - val_prec_under: 0.6351 - val_rec_neutral: 0.2428 - val_rec_over: 0.2659 - val_rec_under: 0.2717 - val_top2_acc: 0.8605\n",
      "Epoch 23/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.8608 - loss: 0.4653 - prec_neutral: 0.6817 - prec_over: 0.5891 - prec_under: 0.6321 - rec_neutral: 0.2728 - rec_over: 0.3239 - rec_under: 0.3245 - top2_acc: 0.9742 - val_acc: 0.5515 - val_loss: 0.9791 - val_prec_neutral: 0.5658 - val_prec_over: 0.6133 - val_prec_under: 0.6184 - val_rec_neutral: 0.2486 - val_rec_over: 0.2659 - val_rec_under: 0.2717 - val_top2_acc: 0.8571\n",
      "Epoch 24/30\n",
      "19/19 - 1s - 49ms/step - acc: 0.8733 - loss: 0.4352 - prec_neutral: 0.6695 - prec_over: 0.5884 - prec_under: 0.6061 - rec_neutral: 0.2873 - rec_over: 0.3168 - rec_under: 0.3152 - top2_acc: 0.9767 - val_acc: 0.5548 - val_loss: 0.9862 - val_prec_neutral: 0.5641 - val_prec_over: 0.6420 - val_prec_under: 0.6250 - val_rec_neutral: 0.2543 - val_rec_over: 0.3006 - val_rec_under: 0.2890 - val_top2_acc: 0.8505\n",
      "Epoch 25/30\n",
      "19/19 - 1s - 50ms/step - acc: 0.8867 - loss: 0.4090 - prec_neutral: 0.6737 - prec_over: 0.5916 - prec_under: 0.6088 - rec_neutral: 0.2704 - rec_over: 0.3210 - rec_under: 0.3125 - top2_acc: 0.9733 - val_acc: 0.5615 - val_loss: 0.9971 - val_prec_neutral: 0.5488 - val_prec_over: 0.6437 - val_prec_under: 0.6235 - val_rec_neutral: 0.2601 - val_rec_over: 0.3237 - val_rec_under: 0.3064 - val_top2_acc: 0.8538\n",
      "Epoch 26/30\n",
      "19/19 - 1s - 56ms/step - acc: 0.8900 - loss: 0.3972 - prec_neutral: 0.6764 - prec_over: 0.5964 - prec_under: 0.6158 - rec_neutral: 0.2788 - rec_over: 0.3253 - rec_under: 0.3218 - top2_acc: 0.9783 - val_acc: 0.5515 - val_loss: 1.0095 - val_prec_neutral: 0.5422 - val_prec_over: 0.6477 - val_prec_under: 0.6023 - val_rec_neutral: 0.2601 - val_rec_over: 0.3295 - val_rec_under: 0.3064 - val_top2_acc: 0.8538\n"
     ]
    }
   ],
   "source": [
    "layers = tf.keras.layers\n",
    "metrics = tf.keras.metrics\n",
    "\n",
    "# get the number of timesteps, channels, and static feature\n",
    "n_timesteps = X_train_ts.shape[1]\n",
    "n_channels = X_train_ts.shape[2]\n",
    "n_static = X_train_static_proc.shape[1]\n",
    "\n",
    "\n",
    "# time series branch\n",
    "ts_input = tf.keras.Input(shape=(n_timesteps, n_channels), name=\"ts_input\")\n",
    "\n",
    "# define the time series branch of the convoluted NN\n",
    "# follow similar structure as the neural network trained in part 1\n",
    "# train static branch\n",
    "# add max pooling\n",
    "ts_branch = layers.Conv1D(filters=32, kernel_size=5, activation='relu', padding='causal')(ts_input)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.MaxPooling1D(pool_size=2)(ts_branch)\n",
    "ts_branch = layers.Conv1D(filters=16, kernel_size=3, activation='relu', \n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-3), padding='causal')(ts_branch)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.GlobalAveragePooling1D()(ts_branch)\n",
    "ts_branch = layers.Dropout(0.15)(ts_branch)\n",
    "\n",
    "# now train static branch\n",
    "static_input = tf.keras.Input(shape=(n_static,))\n",
    "# added batch normalization inside raw static input\n",
    "static_branch = layers.BatchNormalization()(static_input)\n",
    "# reduced dense layer neurons to 128\n",
    "static_branch = layers.Dense(128, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(1e-4))(static_branch)\n",
    "static_branch = layers.Dropout(0.2)(static_branch)\n",
    "# merge branches\n",
    "merged = layers.Concatenate()([ts_branch, static_branch])\n",
    "# add dense layer after merging\n",
    "merged = layers.Dense(64, activation='relu')(merged)\n",
    "merged = layers.Dropout(0.3)(merged)\n",
    "output = layers.Dense(3, activation='softmax', name='prediction')(merged)\n",
    "\n",
    "\n",
    "model_conv_ts_static = tf.keras.models.Model(\n",
    "    inputs=[ts_input, static_input],\n",
    "    outputs=output,\n",
    "    name=\"conv1d_ts_plus_static_classifier\"\n",
    ")\n",
    "\n",
    "\n",
    "top2_acc_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=2,\n",
    "    name=\"top2_accuracy\"\n",
    ")\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model_conv_ts_static.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        metrics.SparseTopKCategoricalAccuracy(k=2, name='top2_acc'),\n",
    "        metrics.Precision(name='prec_under', class_id=0),\n",
    "        metrics.Recall(name='rec_under', class_id=0),\n",
    "        metrics.Precision(name='prec_neutral', class_id=1),\n",
    "        metrics.Recall(name='rec_neutral', class_id=1),\n",
    "        metrics.Precision(name='prec_over', class_id=2),\n",
    "        metrics.Recall(name='rec_over', class_id=2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# train model\n",
    "history = model_conv_ts_static.fit(\n",
    "    [X_train_ts, X_train_static_proc],  # both inputs\n",
    "    y_train,\n",
    "    validation_data=([X_test_ts, X_test_static_proc], y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a769fbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - 98ms/step - acc: 0.5449 - loss: 0.9689 - prec_neutral: 0.7121 - prec_over: 0.5972 - prec_under: 0.8310 - rec_neutral: 0.2293 - rec_over: 0.2240 - rec_under: 0.2489 - top2_acc: 0.8605\n",
      "loss: 0.9689\n",
      "compile_metrics: 0.5449\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step\n",
      "Macro F1: 0.5481\n",
      "Weighted F1: 0.5459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       under       0.61      0.61      0.61        93\n",
      "     neutral       0.41      0.42      0.42       104\n",
      "        over       0.63      0.61      0.62       104\n",
      "\n",
      "    accuracy                           0.54       301\n",
      "   macro avg       0.55      0.55      0.55       301\n",
      "weighted avg       0.55      0.54      0.55       301\n",
      "\n",
      "[[57 30  6]\n",
      " [29 44 31]\n",
      " [ 8 33 63]]\n"
     ]
    }
   ],
   "source": [
    "# Keras metrics\n",
    "results = model_conv_ts_static.evaluate(\n",
    "    [X_test_ts, X_test_static_proc],\n",
    "    y_test,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "for name, value in zip(model_conv_ts_static.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Predictions for sklearn metrics\n",
    "probs = model_conv_ts_static.predict([X_test_ts, X_test_static_proc])\n",
    "pred = probs.argmax(axis=1)\n",
    "\n",
    "macro_f1 = f1_score(y_test, pred, average='macro')\n",
    "weighted_f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pred,\n",
    "    target_names=['under', 'neutral', 'over']\n",
    "))\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390634a6",
   "metadata": {},
   "source": [
    "Slight improvement, will now adjust the dense layer after merge to add another layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "39dc83f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/19 - 9s - 476ms/step - acc: 0.3258 - loss: 1.4038 - prec_neutral: 0.6703 - prec_over: 0.6171 - prec_under: 0.6212 - rec_neutral: 0.2224 - rec_over: 0.1534 - rec_under: 0.1636 - top2_acc: 0.6542 - val_acc: 0.3555 - val_loss: 1.2328 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7010\n",
      "Epoch 2/30\n",
      "19/19 - 1s - 77ms/step - acc: 0.3925 - loss: 1.3108 - prec_neutral: 0.6910 - prec_over: 0.6193 - prec_under: 0.6462 - rec_neutral: 0.1935 - rec_over: 0.1548 - rec_under: 0.1676 - top2_acc: 0.7117 - val_acc: 0.3920 - val_loss: 1.2251 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7276\n",
      "Epoch 3/30\n",
      "19/19 - 1s - 60ms/step - acc: 0.4100 - loss: 1.2598 - prec_neutral: 0.6653 - prec_over: 0.5767 - prec_under: 0.5812 - rec_neutral: 0.1887 - rec_over: 0.1548 - rec_under: 0.1476 - top2_acc: 0.7258 - val_acc: 0.4020 - val_loss: 1.2181 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7276\n",
      "Epoch 4/30\n",
      "19/19 - 1s - 63ms/step - acc: 0.4633 - loss: 1.2085 - prec_neutral: 0.7533 - prec_over: 0.5778 - prec_under: 0.6025 - rec_neutral: 0.2055 - rec_over: 0.1477 - rec_under: 0.1915 - top2_acc: 0.7608 - val_acc: 0.4219 - val_loss: 1.2119 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7508\n",
      "Epoch 5/30\n",
      "19/19 - 1s - 59ms/step - acc: 0.4883 - loss: 1.1820 - prec_neutral: 0.6891 - prec_over: 0.5808 - prec_under: 0.6383 - rec_neutral: 0.1971 - rec_over: 0.1378 - rec_under: 0.1995 - top2_acc: 0.7825 - val_acc: 0.4385 - val_loss: 1.2053 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7409\n",
      "Epoch 6/30\n",
      "19/19 - 1s - 58ms/step - acc: 0.5167 - loss: 1.1438 - prec_neutral: 0.7175 - prec_over: 0.5635 - prec_under: 0.6223 - rec_neutral: 0.1923 - rec_over: 0.1577 - rec_under: 0.1928 - top2_acc: 0.8017 - val_acc: 0.4352 - val_loss: 1.1985 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7475\n",
      "Epoch 7/30\n",
      "19/19 - 1s - 58ms/step - acc: 0.5383 - loss: 1.1089 - prec_neutral: 0.6869 - prec_over: 0.6039 - prec_under: 0.6147 - rec_neutral: 0.1767 - rec_over: 0.1776 - rec_under: 0.1782 - top2_acc: 0.8183 - val_acc: 0.4518 - val_loss: 1.1912 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7575\n",
      "Epoch 8/30\n",
      "19/19 - 1s - 60ms/step - acc: 0.5492 - loss: 1.0828 - prec_neutral: 0.6667 - prec_over: 0.6154 - prec_under: 0.6064 - rec_neutral: 0.1755 - rec_over: 0.1705 - rec_under: 0.2008 - top2_acc: 0.8200 - val_acc: 0.4585 - val_loss: 1.1833 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7542\n",
      "Epoch 9/30\n",
      "19/19 - 1s - 60ms/step - acc: 0.5625 - loss: 1.0440 - prec_neutral: 0.6761 - prec_over: 0.5707 - prec_under: 0.5896 - rec_neutral: 0.1731 - rec_over: 0.1662 - rec_under: 0.1968 - top2_acc: 0.8567 - val_acc: 0.4618 - val_loss: 1.1751 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.3333 - val_prec_under: 1.0000 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0058 - val_rec_under: 0.0058 - val_top2_acc: 0.7475\n",
      "Epoch 10/30\n",
      "19/19 - 1s - 59ms/step - acc: 0.5858 - loss: 1.0176 - prec_neutral: 0.6699 - prec_over: 0.5991 - prec_under: 0.6224 - rec_neutral: 0.1659 - rec_over: 0.1889 - rec_under: 0.2367 - top2_acc: 0.8475 - val_acc: 0.4751 - val_loss: 1.1668 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5714 - val_prec_under: 0.6000 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0231 - val_rec_under: 0.0173 - val_top2_acc: 0.7409\n",
      "Epoch 11/30\n",
      "19/19 - 1s - 60ms/step - acc: 0.5950 - loss: 1.0021 - prec_neutral: 0.7048 - prec_over: 0.5668 - prec_under: 0.6138 - rec_neutral: 0.1923 - rec_over: 0.1989 - rec_under: 0.2367 - top2_acc: 0.8558 - val_acc: 0.4917 - val_loss: 1.1579 - val_prec_neutral: 0.3333 - val_prec_over: 0.5714 - val_prec_under: 0.5556 - val_rec_neutral: 0.0058 - val_rec_over: 0.0231 - val_rec_under: 0.0289 - val_top2_acc: 0.7508\n",
      "Epoch 12/30\n",
      "19/19 - 1s - 61ms/step - acc: 0.6067 - loss: 0.9836 - prec_neutral: 0.7112 - prec_over: 0.5820 - prec_under: 0.6130 - rec_neutral: 0.1983 - rec_over: 0.2017 - rec_under: 0.2380 - top2_acc: 0.8617 - val_acc: 0.5050 - val_loss: 1.1486 - val_prec_neutral: 0.4000 - val_prec_over: 0.7500 - val_prec_under: 0.5000 - val_rec_neutral: 0.0116 - val_rec_over: 0.0520 - val_rec_under: 0.0520 - val_top2_acc: 0.7608\n",
      "Epoch 13/30\n",
      "19/19 - 1s - 56ms/step - acc: 0.6358 - loss: 0.9452 - prec_neutral: 0.6798 - prec_over: 0.5979 - prec_under: 0.6472 - rec_neutral: 0.1659 - rec_over: 0.2429 - rec_under: 0.2660 - top2_acc: 0.8858 - val_acc: 0.5050 - val_loss: 1.1395 - val_prec_neutral: 0.5556 - val_prec_over: 0.6875 - val_prec_under: 0.5217 - val_rec_neutral: 0.0289 - val_rec_over: 0.0636 - val_rec_under: 0.0694 - val_top2_acc: 0.7674\n",
      "Epoch 14/30\n",
      "19/19 - 1s - 54ms/step - acc: 0.6708 - loss: 0.9156 - prec_neutral: 0.6955 - prec_over: 0.5874 - prec_under: 0.6026 - rec_neutral: 0.1839 - rec_over: 0.2244 - rec_under: 0.2420 - top2_acc: 0.8842 - val_acc: 0.5017 - val_loss: 1.1306 - val_prec_neutral: 0.5385 - val_prec_over: 0.7083 - val_prec_under: 0.5769 - val_rec_neutral: 0.0405 - val_rec_over: 0.0983 - val_rec_under: 0.0867 - val_top2_acc: 0.7807\n",
      "Epoch 15/30\n",
      "19/19 - 1s - 56ms/step - acc: 0.6658 - loss: 0.8875 - prec_neutral: 0.7090 - prec_over: 0.6140 - prec_under: 0.6144 - rec_neutral: 0.2284 - rec_over: 0.2372 - rec_under: 0.2606 - top2_acc: 0.8967 - val_acc: 0.5050 - val_loss: 1.1214 - val_prec_neutral: 0.4667 - val_prec_over: 0.7000 - val_prec_under: 0.5882 - val_rec_neutral: 0.0405 - val_rec_over: 0.1214 - val_rec_under: 0.1156 - val_top2_acc: 0.7841\n",
      "Epoch 16/30\n",
      "19/19 - 1s - 58ms/step - acc: 0.6792 - loss: 0.8587 - prec_neutral: 0.6682 - prec_over: 0.5974 - prec_under: 0.6261 - rec_neutral: 0.1791 - rec_over: 0.2614 - rec_under: 0.2872 - top2_acc: 0.9142 - val_acc: 0.5050 - val_loss: 1.1127 - val_prec_neutral: 0.4762 - val_prec_over: 0.6875 - val_prec_under: 0.6250 - val_rec_neutral: 0.0578 - val_rec_over: 0.1272 - val_rec_under: 0.1445 - val_top2_acc: 0.7841\n",
      "Epoch 17/30\n",
      "19/19 - 1s - 61ms/step - acc: 0.7025 - loss: 0.8270 - prec_neutral: 0.6716 - prec_over: 0.5915 - prec_under: 0.6202 - rec_neutral: 0.2188 - rec_over: 0.2571 - rec_under: 0.2779 - top2_acc: 0.9125 - val_acc: 0.5050 - val_loss: 1.1045 - val_prec_neutral: 0.5200 - val_prec_over: 0.6829 - val_prec_under: 0.6136 - val_rec_neutral: 0.0751 - val_rec_over: 0.1618 - val_rec_under: 0.1561 - val_top2_acc: 0.7841\n",
      "Epoch 18/30\n",
      "19/19 - 1s - 60ms/step - acc: 0.7083 - loss: 0.8236 - prec_neutral: 0.6977 - prec_over: 0.6044 - prec_under: 0.6036 - rec_neutral: 0.2163 - rec_over: 0.2713 - rec_under: 0.2673 - top2_acc: 0.9050 - val_acc: 0.5083 - val_loss: 1.0983 - val_prec_neutral: 0.4839 - val_prec_over: 0.6667 - val_prec_under: 0.6000 - val_rec_neutral: 0.0867 - val_rec_over: 0.1850 - val_rec_under: 0.1734 - val_top2_acc: 0.7841\n",
      "Epoch 19/30\n",
      "19/19 - 1s - 59ms/step - acc: 0.7100 - loss: 0.7853 - prec_neutral: 0.7008 - prec_over: 0.6042 - prec_under: 0.6209 - rec_neutral: 0.2224 - rec_over: 0.2841 - rec_under: 0.2766 - top2_acc: 0.9217 - val_acc: 0.5183 - val_loss: 1.0927 - val_prec_neutral: 0.5405 - val_prec_over: 0.6207 - val_prec_under: 0.5893 - val_rec_neutral: 0.1156 - val_rec_over: 0.2081 - val_rec_under: 0.1908 - val_top2_acc: 0.7940\n",
      "Epoch 20/30\n",
      "19/19 - 1s - 68ms/step - acc: 0.7325 - loss: 0.7726 - prec_neutral: 0.7073 - prec_over: 0.6042 - prec_under: 0.6199 - rec_neutral: 0.2440 - rec_over: 0.2841 - rec_under: 0.2819 - top2_acc: 0.9233 - val_acc: 0.5116 - val_loss: 1.0884 - val_prec_neutral: 0.5366 - val_prec_over: 0.6290 - val_prec_under: 0.5938 - val_rec_neutral: 0.1272 - val_rec_over: 0.2254 - val_rec_under: 0.2197 - val_top2_acc: 0.7907\n",
      "Epoch 21/30\n",
      "19/19 - 1s - 59ms/step - acc: 0.7442 - loss: 0.7508 - prec_neutral: 0.7070 - prec_over: 0.5854 - prec_under: 0.6438 - rec_neutral: 0.2320 - rec_over: 0.2727 - rec_under: 0.3125 - top2_acc: 0.9250 - val_acc: 0.5282 - val_loss: 1.0841 - val_prec_neutral: 0.5333 - val_prec_over: 0.6250 - val_prec_under: 0.6119 - val_rec_neutral: 0.1387 - val_rec_over: 0.2312 - val_rec_under: 0.2370 - val_top2_acc: 0.8040\n",
      "Epoch 22/30\n",
      "19/19 - 1s - 55ms/step - acc: 0.7533 - loss: 0.7242 - prec_neutral: 0.6667 - prec_over: 0.5937 - prec_under: 0.6271 - rec_neutral: 0.2260 - rec_over: 0.2926 - rec_under: 0.3019 - top2_acc: 0.9317 - val_acc: 0.5316 - val_loss: 1.0827 - val_prec_neutral: 0.5849 - val_prec_over: 0.6471 - val_prec_under: 0.6143 - val_rec_neutral: 0.1792 - val_rec_over: 0.2543 - val_rec_under: 0.2486 - val_top2_acc: 0.8106\n",
      "Epoch 23/30\n",
      "19/19 - 1s - 56ms/step - acc: 0.7792 - loss: 0.6973 - prec_neutral: 0.6814 - prec_over: 0.5983 - prec_under: 0.6247 - rec_neutral: 0.2416 - rec_over: 0.2983 - rec_under: 0.3032 - top2_acc: 0.9317 - val_acc: 0.5316 - val_loss: 1.0837 - val_prec_neutral: 0.5833 - val_prec_over: 0.6667 - val_prec_under: 0.6197 - val_rec_neutral: 0.2023 - val_rec_over: 0.2890 - val_rec_under: 0.2543 - val_top2_acc: 0.8073\n",
      "Epoch 24/30\n",
      "19/19 - 1s - 57ms/step - acc: 0.7717 - loss: 0.6893 - prec_neutral: 0.6763 - prec_over: 0.5826 - prec_under: 0.6229 - rec_neutral: 0.2536 - rec_over: 0.2855 - rec_under: 0.2965 - top2_acc: 0.9400 - val_acc: 0.5316 - val_loss: 1.0871 - val_prec_neutral: 0.5692 - val_prec_over: 0.6750 - val_prec_under: 0.6111 - val_rec_neutral: 0.2139 - val_rec_over: 0.3121 - val_rec_under: 0.2543 - val_top2_acc: 0.8073\n",
      "Epoch 25/30\n",
      "19/19 - 1s - 57ms/step - acc: 0.7900 - loss: 0.6546 - prec_neutral: 0.6959 - prec_over: 0.5950 - prec_under: 0.6177 - rec_neutral: 0.2668 - rec_over: 0.3026 - rec_under: 0.2965 - top2_acc: 0.9533 - val_acc: 0.5349 - val_loss: 1.0949 - val_prec_neutral: 0.5606 - val_prec_over: 0.6709 - val_prec_under: 0.6027 - val_rec_neutral: 0.2139 - val_rec_over: 0.3064 - val_rec_under: 0.2543 - val_top2_acc: 0.8073\n",
      "Epoch 26/30\n",
      "19/19 - 1s - 54ms/step - acc: 0.8042 - loss: 0.6417 - prec_neutral: 0.6955 - prec_over: 0.5843 - prec_under: 0.6450 - rec_neutral: 0.2608 - rec_over: 0.2955 - rec_under: 0.3165 - top2_acc: 0.9492 - val_acc: 0.5382 - val_loss: 1.1027 - val_prec_neutral: 0.5775 - val_prec_over: 0.6667 - val_prec_under: 0.6203 - val_rec_neutral: 0.2370 - val_rec_over: 0.3237 - val_rec_under: 0.2832 - val_top2_acc: 0.8106\n",
      "Epoch 27/30\n",
      "19/19 - 1s - 56ms/step - acc: 0.8275 - loss: 0.5941 - prec_neutral: 0.6968 - prec_over: 0.6180 - prec_under: 0.6319 - rec_neutral: 0.2596 - rec_over: 0.3310 - rec_under: 0.3059 - top2_acc: 0.9592 - val_acc: 0.5515 - val_loss: 1.1112 - val_prec_neutral: 0.5616 - val_prec_over: 0.6628 - val_prec_under: 0.6203 - val_rec_neutral: 0.2370 - val_rec_over: 0.3295 - val_rec_under: 0.2832 - val_top2_acc: 0.8173\n"
     ]
    }
   ],
   "source": [
    "layers = tf.keras.layers\n",
    "metrics = tf.keras.metrics\n",
    "\n",
    "# get the number of timesteps, channels, and static feature\n",
    "n_timesteps = X_train_ts.shape[1]\n",
    "n_channels = X_train_ts.shape[2]\n",
    "n_static = X_train_static_proc.shape[1]\n",
    "\n",
    "\n",
    "# time series branch\n",
    "ts_input = tf.keras.Input(shape=(n_timesteps, n_channels), name=\"ts_input\")\n",
    "\n",
    "# define the time series branch of the convoluted NN\n",
    "# follow similar structure as the neural network trained in part 1\n",
    "# train static branch\n",
    "# add batch normalization to ts branch and remove max pooling\n",
    "ts_branch = layers.Conv1D(filters=32, kernel_size=5, activation='relu', padding='causal')(ts_input)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.SpatialDropout1D(0.1)(ts_branch)\n",
    "ts_branch = layers.Conv1D(filters=64, kernel_size=3, activation='relu', \n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-3), padding='causal')(ts_branch)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.MaxPooling1D(pool_size=2)(ts_branch)\n",
    "ts_branch = layers.GlobalAveragePooling1D()(ts_branch)\n",
    "ts_branch = layers.Dropout(0.15)(ts_branch)\n",
    "\n",
    "# now train static branch\n",
    "static_input = tf.keras.Input(shape=(n_static,))\n",
    "# added batch normalization inside raw static input\n",
    "static_branch = layers.BatchNormalization()(static_input)\n",
    "# reduced dense layer neurons to 128\n",
    "static_branch = layers.Dense(96, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(5e-4))(static_branch)\n",
    "static_branch = layers.Dropout(0.25)(static_branch)\n",
    "# merge branches\n",
    "merged = layers.Concatenate()([ts_branch, static_branch])\n",
    "# add dense layer after merging\n",
    "merged = layers.Dense(48, activation='relu', \n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(1e-4))(merged)\n",
    "merged = layers.Dropout(0.15)(merged)\n",
    "merged = layers.Dense(64, activation='relu')(merged)\n",
    "merged = layers.Dropout(0.1)(merged)\n",
    "output = layers.Dense(3, activation='softmax', name='prediction')(merged)\n",
    "\n",
    "\n",
    "model_conv_ts_static = tf.keras.models.Model(\n",
    "    inputs=[ts_input, static_input],\n",
    "    outputs=output,\n",
    "    name=\"conv1d_ts_plus_static_classifier\"\n",
    ")\n",
    "\n",
    "\n",
    "top2_acc_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=2,\n",
    "    name=\"top2_accuracy\"\n",
    ")\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model_conv_ts_static.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        metrics.SparseTopKCategoricalAccuracy(k=2, name='top2_acc'),\n",
    "        metrics.Precision(name='prec_under', class_id=0),\n",
    "        metrics.Recall(name='rec_under', class_id=0),\n",
    "        metrics.Precision(name='prec_neutral', class_id=1),\n",
    "        metrics.Recall(name='rec_neutral', class_id=1),\n",
    "        metrics.Precision(name='prec_over', class_id=2),\n",
    "        metrics.Recall(name='rec_over', class_id=2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# train model\n",
    "history = model_conv_ts_static.fit(\n",
    "    [X_train_ts, X_train_static_proc],  # both inputs\n",
    "    y_train,\n",
    "    validation_data=([X_test_ts, X_test_static_proc], y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "044ccd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - 114ms/step - acc: 0.5316 - loss: 1.0827 - prec_neutral: 0.6981 - prec_over: 0.6324 - prec_under: 0.8143 - rec_neutral: 0.1805 - rec_over: 0.2240 - rec_under: 0.2405 - top2_acc: 0.8106\n",
      "loss: 1.0827\n",
      "compile_metrics: 0.5316\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n",
      "Macro F1: 0.5311\n",
      "Weighted F1: 0.5300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       under       0.57      0.56      0.56        93\n",
      "     neutral       0.43      0.41      0.42       104\n",
      "        over       0.59      0.62      0.61       104\n",
      "\n",
      "    accuracy                           0.53       301\n",
      "   macro avg       0.53      0.53      0.53       301\n",
      "weighted avg       0.53      0.53      0.53       301\n",
      "\n",
      "[[52 26 15]\n",
      " [31 43 30]\n",
      " [ 9 30 65]]\n"
     ]
    }
   ],
   "source": [
    "# Keras metrics\n",
    "results = model_conv_ts_static.evaluate(\n",
    "    [X_test_ts, X_test_static_proc],\n",
    "    y_test,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "for name, value in zip(model_conv_ts_static.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Predictions for sklearn metrics\n",
    "probs = model_conv_ts_static.predict([X_test_ts, X_test_static_proc])\n",
    "pred = probs.argmax(axis=1)\n",
    "\n",
    "macro_f1 = f1_score(y_test, pred, average='macro')\n",
    "weighted_f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pred,\n",
    "    target_names=['under', 'neutral', 'over']\n",
    "))\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a4bee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/19 - 5s - 240ms/step - acc: 0.3542 - loss: 1.4168 - prec_neutral: 0.6548 - prec_over: 0.6043 - prec_under: 0.7709 - rec_neutral: 0.1581 - rec_over: 0.2442 - rec_under: 0.2830 - top2_acc: 0.6817 - val_acc: 0.3355 - val_loss: 1.1662 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.6977\n",
      "Epoch 2/30\n",
      "19/19 - 1s - 42ms/step - acc: 0.4492 - loss: 1.2010 - prec_neutral: 0.7672 - prec_over: 0.6220 - prec_under: 0.6486 - rec_neutral: 0.1510 - rec_over: 0.2357 - rec_under: 0.2331 - top2_acc: 0.7517 - val_acc: 0.3555 - val_loss: 1.1567 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7043\n",
      "Epoch 3/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.4483 - loss: 1.1492 - prec_neutral: 0.5628 - prec_over: 0.6000 - prec_under: 0.6077 - rec_neutral: 0.1750 - rec_over: 0.2529 - rec_under: 0.2101 - top2_acc: 0.7733 - val_acc: 0.3588 - val_loss: 1.1471 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.2500 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0058 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7043\n",
      "Epoch 4/30\n",
      "19/19 - 1s - 44ms/step - acc: 0.5100 - loss: 1.0522 - prec_neutral: 0.5311 - prec_over: 0.6908 - prec_under: 0.8030 - rec_neutral: 0.1366 - rec_over: 0.2524 - rec_under: 0.2288 - top2_acc: 0.8233 - val_acc: 0.3754 - val_loss: 1.1370 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.4286 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0173 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7309\n",
      "Epoch 5/30\n",
      "19/19 - 1s - 46ms/step - acc: 0.5558 - loss: 1.0074 - prec_neutral: 0.8090 - prec_over: 0.7559 - prec_under: 0.7980 - rec_neutral: 0.1706 - rec_over: 0.2568 - rec_under: 0.2553 - top2_acc: 0.8467 - val_acc: 0.4020 - val_loss: 1.1275 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.6364 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0405 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7641\n",
      "Epoch 6/30\n",
      "19/19 - 1s - 45ms/step - acc: 0.5783 - loss: 0.9593 - prec_neutral: 0.8030 - prec_over: 0.4590 - prec_under: 0.4172 - rec_neutral: 0.1684 - rec_over: 0.2500 - rec_under: 0.2440 - top2_acc: 0.8675 - val_acc: 0.4319 - val_loss: 1.1171 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.6154 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0462 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7741\n",
      "Epoch 7/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.5942 - loss: 0.9498 - prec_neutral: 0.4860 - prec_over: 0.5743 - prec_under: 0.7706 - rec_neutral: 0.1667 - rec_over: 0.2529 - rec_under: 0.2669 - top2_acc: 0.8750 - val_acc: 0.4718 - val_loss: 1.1071 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.6250 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0578 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7940\n",
      "Epoch 8/30\n",
      "19/19 - 1s - 45ms/step - acc: 0.6192 - loss: 0.8968 - prec_neutral: 0.6044 - prec_over: 0.5916 - prec_under: 0.7674 - rec_neutral: 0.1932 - rec_over: 0.2614 - rec_under: 0.2797 - top2_acc: 0.8825 - val_acc: 0.4751 - val_loss: 1.0986 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5789 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0636 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7973\n",
      "Epoch 9/30\n",
      "19/19 - 1s - 44ms/step - acc: 0.6433 - loss: 0.8548 - prec_neutral: 0.7004 - prec_over: 0.6188 - prec_under: 0.6426 - rec_neutral: 0.1995 - rec_over: 0.2806 - rec_under: 0.2846 - top2_acc: 0.9042 - val_acc: 0.4817 - val_loss: 1.0890 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.5714 - val_prec_under: 1.0000 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0694 - val_rec_under: 0.0116 - val_top2_acc: 0.8040\n",
      "Epoch 10/30\n",
      "19/19 - 1s - 44ms/step - acc: 0.6592 - loss: 0.8232 - prec_neutral: 0.6862 - prec_over: 0.6873 - prec_under: 0.6686 - rec_neutral: 0.1971 - rec_over: 0.2668 - rec_under: 0.2995 - top2_acc: 0.9025 - val_acc: 0.4817 - val_loss: 1.0786 - val_prec_neutral: 0.7500 - val_prec_over: 0.6071 - val_prec_under: 0.7143 - val_rec_neutral: 0.0173 - val_rec_over: 0.0983 - val_rec_under: 0.0289 - val_top2_acc: 0.8040\n",
      "Epoch 11/30\n",
      "19/19 - 1s - 45ms/step - acc: 0.7000 - loss: 0.7805 - prec_neutral: 0.7799 - prec_over: 0.5254 - prec_under: 0.6398 - rec_neutral: 0.2140 - rec_over: 0.2750 - rec_under: 0.2721 - top2_acc: 0.9267 - val_acc: 0.4884 - val_loss: 1.0687 - val_prec_neutral: 0.6667 - val_prec_over: 0.6000 - val_prec_under: 0.6154 - val_rec_neutral: 0.0231 - val_rec_over: 0.1214 - val_rec_under: 0.0462 - val_top2_acc: 0.8173\n",
      "Epoch 12/30\n",
      "19/19 - 1s - 44ms/step - acc: 0.7083 - loss: 0.7657 - prec_neutral: 0.6609 - prec_over: 0.5994 - prec_under: 0.9101 - rec_neutral: 0.1887 - rec_over: 0.2912 - rec_under: 0.2929 - top2_acc: 0.9250 - val_acc: 0.5083 - val_loss: 1.0597 - val_prec_neutral: 0.6000 - val_prec_over: 0.5641 - val_prec_under: 0.6667 - val_rec_neutral: 0.0347 - val_rec_over: 0.1272 - val_rec_under: 0.0694 - val_top2_acc: 0.8239\n",
      "Epoch 13/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.7250 - loss: 0.7422 - prec_neutral: 0.5407 - prec_over: 0.6519 - prec_under: 0.6228 - rec_neutral: 0.2074 - rec_over: 0.2708 - rec_under: 0.2832 - top2_acc: 0.9275 - val_acc: 0.5050 - val_loss: 1.0514 - val_prec_neutral: 0.5714 - val_prec_over: 0.5532 - val_prec_under: 0.7083 - val_rec_neutral: 0.0462 - val_rec_over: 0.1503 - val_rec_under: 0.0983 - val_top2_acc: 0.8206\n",
      "Epoch 14/30\n",
      "19/19 - 1s - 41ms/step - acc: 0.7542 - loss: 0.7011 - prec_neutral: 0.7372 - prec_over: 0.5726 - prec_under: 0.8288 - rec_neutral: 0.2295 - rec_over: 0.2922 - rec_under: 0.3026 - top2_acc: 0.9358 - val_acc: 0.5183 - val_loss: 1.0443 - val_prec_neutral: 0.4615 - val_prec_over: 0.5882 - val_prec_under: 0.6667 - val_rec_neutral: 0.0694 - val_rec_over: 0.1734 - val_rec_under: 0.1156 - val_top2_acc: 0.8272\n",
      "Epoch 15/30\n",
      "19/19 - 1s - 44ms/step - acc: 0.7367 - loss: 0.7046 - prec_neutral: 0.7678 - prec_over: 0.7471 - prec_under: 0.4767 - rec_neutral: 0.2330 - rec_over: 0.2868 - rec_under: 0.3021 - top2_acc: 0.9425 - val_acc: 0.5150 - val_loss: 1.0372 - val_prec_neutral: 0.4688 - val_prec_over: 0.6038 - val_prec_under: 0.6389 - val_rec_neutral: 0.0867 - val_rec_over: 0.1850 - val_rec_under: 0.1329 - val_top2_acc: 0.8306\n",
      "Epoch 16/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.7558 - loss: 0.6638 - prec_neutral: 0.6259 - prec_over: 0.6932 - prec_under: 0.7318 - rec_neutral: 0.2247 - rec_over: 0.2990 - rec_under: 0.3193 - top2_acc: 0.9450 - val_acc: 0.5183 - val_loss: 1.0312 - val_prec_neutral: 0.4722 - val_prec_over: 0.6316 - val_prec_under: 0.6667 - val_rec_neutral: 0.0983 - val_rec_over: 0.2081 - val_rec_under: 0.1618 - val_top2_acc: 0.8306\n",
      "Epoch 17/30\n",
      "19/19 - 1s - 41ms/step - acc: 0.7775 - loss: 0.6403 - prec_neutral: 0.7129 - prec_over: 0.5892 - prec_under: 0.6770 - rec_neutral: 0.2467 - rec_over: 0.2955 - rec_under: 0.2953 - top2_acc: 0.9533 - val_acc: 0.5150 - val_loss: 1.0272 - val_prec_neutral: 0.5000 - val_prec_over: 0.6207 - val_prec_under: 0.6304 - val_rec_neutral: 0.1156 - val_rec_over: 0.2081 - val_rec_under: 0.1676 - val_top2_acc: 0.8372\n",
      "Epoch 18/30\n",
      "19/19 - 1s - 44ms/step - acc: 0.8017 - loss: 0.6247 - prec_neutral: 0.5925 - prec_over: 0.7921 - prec_under: 0.6821 - rec_neutral: 0.2457 - rec_over: 0.2987 - rec_under: 0.3197 - top2_acc: 0.9550 - val_acc: 0.5116 - val_loss: 1.0229 - val_prec_neutral: 0.5000 - val_prec_over: 0.6406 - val_prec_under: 0.6400 - val_rec_neutral: 0.1329 - val_rec_over: 0.2370 - val_rec_under: 0.1850 - val_top2_acc: 0.8372\n",
      "Epoch 19/30\n",
      "19/19 - 1s - 41ms/step - acc: 0.8092 - loss: 0.5747 - prec_neutral: 0.6842 - prec_over: 0.7205 - prec_under: 0.6237 - rec_neutral: 0.2549 - rec_over: 0.2989 - rec_under: 0.3152 - top2_acc: 0.9725 - val_acc: 0.5249 - val_loss: 1.0216 - val_prec_neutral: 0.5000 - val_prec_over: 0.6462 - val_prec_under: 0.6471 - val_rec_neutral: 0.1561 - val_rec_over: 0.2428 - val_rec_under: 0.1908 - val_top2_acc: 0.8272\n",
      "Epoch 20/30\n",
      "19/19 - 1s - 40ms/step - acc: 0.8108 - loss: 0.5739 - prec_neutral: 0.7893 - prec_over: 0.8529 - prec_under: 0.6237 - rec_neutral: 0.2659 - rec_over: 0.3105 - rec_under: 0.3086 - top2_acc: 0.9592 - val_acc: 0.5216 - val_loss: 1.0242 - val_prec_neutral: 0.5085 - val_prec_over: 0.6269 - val_prec_under: 0.6429 - val_rec_neutral: 0.1734 - val_rec_over: 0.2428 - val_rec_under: 0.2081 - val_top2_acc: 0.8239\n",
      "Epoch 21/30\n",
      "19/19 - 1s - 40ms/step - acc: 0.8317 - loss: 0.5435 - prec_neutral: 0.6888 - prec_over: 0.9440 - prec_under: 0.6747 - rec_neutral: 0.2740 - rec_over: 0.2967 - rec_under: 0.3076 - top2_acc: 0.9675 - val_acc: 0.5183 - val_loss: 1.0267 - val_prec_neutral: 0.5156 - val_prec_over: 0.6286 - val_prec_under: 0.6557 - val_rec_neutral: 0.1908 - val_rec_over: 0.2543 - val_rec_under: 0.2312 - val_top2_acc: 0.8339\n",
      "Epoch 22/30\n",
      "19/19 - 1s - 42ms/step - acc: 0.8442 - loss: 0.5118 - prec_neutral: 0.6048 - prec_over: 0.6120 - prec_under: 0.5141 - rec_neutral: 0.2686 - rec_over: 0.2979 - rec_under: 0.3221 - top2_acc: 0.9700 - val_acc: 0.5116 - val_loss: 1.0300 - val_prec_neutral: 0.5231 - val_prec_over: 0.6197 - val_prec_under: 0.6338 - val_rec_neutral: 0.1965 - val_rec_over: 0.2543 - val_rec_under: 0.2601 - val_top2_acc: 0.8405\n",
      "Epoch 23/30\n",
      "19/19 - 1s - 41ms/step - acc: 0.8433 - loss: 0.5089 - prec_neutral: 0.5335 - prec_over: 0.6312 - prec_under: 0.6378 - rec_neutral: 0.2609 - rec_over: 0.3231 - rec_under: 0.3255 - top2_acc: 0.9658 - val_acc: 0.5216 - val_loss: 1.0364 - val_prec_neutral: 0.5075 - val_prec_over: 0.6133 - val_prec_under: 0.6250 - val_rec_neutral: 0.1965 - val_rec_over: 0.2659 - val_rec_under: 0.2601 - val_top2_acc: 0.8339\n",
      "Epoch 24/30\n",
      "19/19 - 1s - 46ms/step - acc: 0.8550 - loss: 0.4874 - prec_neutral: 0.5385 - prec_over: 0.8079 - prec_under: 0.8935 - rec_neutral: 0.2734 - rec_over: 0.3252 - rec_under: 0.3209 - top2_acc: 0.9725 - val_acc: 0.5282 - val_loss: 1.0470 - val_prec_neutral: 0.5395 - val_prec_over: 0.6000 - val_prec_under: 0.6351 - val_rec_neutral: 0.2370 - val_rec_over: 0.2601 - val_rec_under: 0.2717 - val_top2_acc: 0.8472\n"
     ]
    }
   ],
   "source": [
    "layers = tf.keras.layers\n",
    "metrics = tf.keras.metrics\n",
    "\n",
    "# get the number of timesteps, channels, and static feature\n",
    "n_timesteps = X_train_ts.shape[1]\n",
    "n_channels = X_train_ts.shape[2]\n",
    "n_static = X_train_static_proc.shape[1]\n",
    "\n",
    "\n",
    "# time series branch\n",
    "ts_input = tf.keras.Input(shape=(n_timesteps, n_channels), name=\"ts_input\")\n",
    "\n",
    "# define the time series branch of the convoluted NN\n",
    "# follow similar structure as the neural network trained in part 1\n",
    "# train static branch\n",
    "# add batch normalization to ts branch\n",
    "ts_branch = layers.Conv1D(filters=32, kernel_size=5, activation='relu', padding='causal')(ts_input)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.SpatialDropout1D(0.1)(ts_branch)\n",
    "ts_branch = layers.Conv1D(filters=64, kernel_size=3, activation='relu', \n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-3), padding='causal')(ts_branch)\n",
    "ts_branch = layers.BatchNormalization()(ts_branch)\n",
    "ts_branch = layers.MaxPooling1D(pool_size=2)(ts_branch)\n",
    "ts_branch = layers.GlobalAveragePooling1D()(ts_branch)\n",
    "ts_branch = layers.Dropout(0.15)(ts_branch)\n",
    "\n",
    "# now train static branch\n",
    "static_input = tf.keras.Input(shape=(n_static,))\n",
    "# added batch normalization inside raw static input\n",
    "static_branch = layers.BatchNormalization()(static_input)\n",
    "# reduced dense layer neurons to 128\n",
    "static_branch = layers.Dense(128, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(1e-4))(static_branch)\n",
    "static_branch = layers.Dropout(0.2)(static_branch)\n",
    "# merge branches\n",
    "merged = layers.Concatenate()([ts_branch, static_branch])\n",
    "# add dense layer after merging\n",
    "merged = layers.Dense(64, activation='relu')(merged)\n",
    "merged = layers.Dropout(0.3)(merged)\n",
    "output = layers.Dense(3, activation='softmax', name='prediction')(merged)\n",
    "\n",
    "\n",
    "model_conv_ts_static = tf.keras.models.Model(\n",
    "    inputs=[ts_input, static_input],\n",
    "    outputs=output,\n",
    "    name=\"conv1d_ts_plus_static_classifier\"\n",
    ")\n",
    "\n",
    "\n",
    "top2_acc_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=2,\n",
    "    name=\"top2_accuracy\"\n",
    ")\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model_conv_ts_static.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        metrics.SparseTopKCategoricalAccuracy(k=2, name='top2_acc'),\n",
    "        metrics.Precision(name='prec_under', class_id=0),\n",
    "        metrics.Recall(name='rec_under', class_id=0),\n",
    "        metrics.Precision(name='prec_neutral', class_id=1),\n",
    "        metrics.Recall(name='rec_neutral', class_id=1),\n",
    "        metrics.Precision(name='prec_over', class_id=2),\n",
    "        metrics.Recall(name='rec_over', class_id=2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# train model\n",
    "history = model_conv_ts_static.fit(\n",
    "    [X_train_ts, X_train_static_proc],  # both inputs\n",
    "    y_train,\n",
    "    validation_data=([X_test_ts, X_test_static_proc], y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a4c4494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - 49ms/step - acc: 0.5249 - loss: 1.0216 - prec_neutral: 0.6111 - prec_over: 0.6769 - prec_under: 0.8039 - rec_neutral: 0.1610 - rec_over: 0.2292 - rec_under: 0.1730 - top2_acc: 0.8272\n",
      "loss: 1.0216\n",
      "compile_metrics: 0.5249\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "Macro F1: 0.5269\n",
      "Weighted F1: 0.5249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       under       0.59      0.58      0.58        93\n",
      "     neutral       0.38      0.38      0.38       104\n",
      "        over       0.61      0.62      0.61       104\n",
      "\n",
      "    accuracy                           0.52       301\n",
      "   macro avg       0.53      0.53      0.53       301\n",
      "weighted avg       0.52      0.52      0.52       301\n",
      "\n",
      "[[54 33  6]\n",
      " [29 40 35]\n",
      " [ 9 31 64]]\n"
     ]
    }
   ],
   "source": [
    "# Keras metrics\n",
    "results = model_conv_ts_static.evaluate(\n",
    "    [X_test_ts, X_test_static_proc],\n",
    "    y_test,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "for name, value in zip(model_conv_ts_static.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Predictions for sklearn metrics\n",
    "probs = model_conv_ts_static.predict([X_test_ts, X_test_static_proc])\n",
    "pred = probs.argmax(axis=1)\n",
    "\n",
    "macro_f1 = f1_score(y_test, pred, average='macro')\n",
    "weighted_f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pred,\n",
    "    target_names=['under', 'neutral', 'over']\n",
    "))\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98462529",
   "metadata": {},
   "source": [
    "Performance is worse so we will try two more changes before sticking with the last model we had with the best performance\n",
    "Attempt to increase weight of neutral class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb4c03ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/19 - 5s - 281ms/step - acc: 0.3467 - loss: 1.5896 - prec_neutral: 0.6084 - prec_over: 0.6163 - prec_under: 0.5425 - rec_neutral: 0.2500 - rec_over: 0.2070 - rec_under: 0.2594 - top2_acc: 0.6667 - val_acc: 0.3621 - val_loss: 1.1420 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.6977\n",
      "Epoch 2/30\n",
      "19/19 - 1s - 51ms/step - acc: 0.3900 - loss: 1.4218 - prec_neutral: 0.7774 - prec_over: 0.6908 - prec_under: 0.5664 - rec_neutral: 0.2331 - rec_over: 0.2057 - rec_under: 0.2266 - top2_acc: 0.7267 - val_acc: 0.3688 - val_loss: 1.1340 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7143\n",
      "Epoch 3/30\n",
      "19/19 - 1s - 48ms/step - acc: 0.4517 - loss: 1.3163 - prec_neutral: 0.8000 - prec_over: 0.6174 - prec_under: 0.5808 - rec_neutral: 0.2585 - rec_over: 0.2447 - rec_under: 0.2145 - top2_acc: 0.7733 - val_acc: 0.3887 - val_loss: 1.1261 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7176\n",
      "Epoch 4/30\n",
      "19/19 - 1s - 48ms/step - acc: 0.4958 - loss: 1.2331 - prec_neutral: 0.7459 - prec_over: 0.7778 - prec_under: 0.7481 - rec_neutral: 0.2522 - rec_over: 0.2299 - rec_under: 0.2227 - top2_acc: 0.7742 - val_acc: 0.3821 - val_loss: 1.1187 - val_prec_neutral: 0.0000e+00 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0000e+00 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7243\n",
      "Epoch 5/30\n",
      "19/19 - 1s - 47ms/step - acc: 0.5000 - loss: 1.1850 - prec_neutral: 0.7454 - prec_over: 0.5812 - prec_under: 0.6166 - rec_neutral: 0.2761 - rec_over: 0.2340 - rec_under: 0.2074 - top2_acc: 0.8017 - val_acc: 0.3987 - val_loss: 1.1091 - val_prec_neutral: 0.6000 - val_prec_over: 0.0000e+00 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0173 - val_rec_over: 0.0000e+00 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7409\n",
      "Epoch 6/30\n",
      "19/19 - 1s - 44ms/step - acc: 0.5517 - loss: 1.0633 - prec_neutral: 0.7238 - prec_over: 0.4856 - prec_under: 0.7090 - rec_neutral: 0.2779 - rec_over: 0.2344 - rec_under: 0.2159 - top2_acc: 0.8417 - val_acc: 0.4153 - val_loss: 1.1004 - val_prec_neutral: 0.5556 - val_prec_over: 0.3333 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0289 - val_rec_over: 0.0058 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7608\n",
      "Epoch 7/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.5725 - loss: 1.0262 - prec_neutral: 0.4235 - prec_over: 0.6241 - prec_under: 0.7885 - rec_neutral: 0.2571 - rec_over: 0.2227 - rec_under: 0.2292 - top2_acc: 0.8700 - val_acc: 0.4186 - val_loss: 1.0925 - val_prec_neutral: 0.5714 - val_prec_over: 0.2000 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0462 - val_rec_over: 0.0058 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7841\n",
      "Epoch 8/30\n",
      "19/19 - 1s - 46ms/step - acc: 0.6042 - loss: 1.0026 - prec_neutral: 0.4986 - prec_over: 0.6061 - prec_under: 0.5434 - rec_neutral: 0.3179 - rec_over: 0.2128 - rec_under: 0.2093 - top2_acc: 0.8692 - val_acc: 0.4419 - val_loss: 1.0829 - val_prec_neutral: 0.5263 - val_prec_over: 0.4545 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0578 - val_rec_over: 0.0289 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7741\n",
      "Epoch 9/30\n",
      "19/19 - 1s - 48ms/step - acc: 0.6292 - loss: 0.9552 - prec_neutral: 0.6265 - prec_over: 0.5923 - prec_under: 0.6831 - rec_neutral: 0.2832 - rec_over: 0.2471 - rec_under: 0.2377 - top2_acc: 0.8800 - val_acc: 0.4518 - val_loss: 1.0746 - val_prec_neutral: 0.4828 - val_prec_over: 0.5000 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.0809 - val_rec_over: 0.0405 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7807\n",
      "Epoch 10/30\n",
      "19/19 - 1s - 47ms/step - acc: 0.6375 - loss: 0.9140 - prec_neutral: 0.6425 - prec_over: 0.7365 - prec_under: 0.6905 - rec_neutral: 0.3059 - rec_over: 0.2477 - rec_under: 0.2488 - top2_acc: 0.8908 - val_acc: 0.4551 - val_loss: 1.0655 - val_prec_neutral: 0.5000 - val_prec_over: 0.5000 - val_prec_under: 0.0000e+00 - val_rec_neutral: 0.1040 - val_rec_over: 0.0405 - val_rec_under: 0.0000e+00 - val_top2_acc: 0.7907\n",
      "Epoch 11/30\n",
      "19/19 - 1s - 48ms/step - acc: 0.6317 - loss: 0.9214 - prec_neutral: 0.7450 - prec_over: 0.9217 - prec_under: 0.7929 - rec_neutral: 0.2989 - rec_over: 0.2416 - rec_under: 0.2552 - top2_acc: 0.9108 - val_acc: 0.4817 - val_loss: 1.0576 - val_prec_neutral: 0.5333 - val_prec_over: 0.5000 - val_prec_under: 0.4000 - val_rec_neutral: 0.1387 - val_rec_over: 0.0520 - val_rec_under: 0.0116 - val_top2_acc: 0.7940\n",
      "Epoch 12/30\n",
      "19/19 - 1s - 47ms/step - acc: 0.6808 - loss: 0.8346 - prec_neutral: 0.5378 - prec_over: 0.5282 - prec_under: 0.7264 - rec_neutral: 0.3109 - rec_over: 0.2404 - rec_under: 0.2625 - top2_acc: 0.9100 - val_acc: 0.4850 - val_loss: 1.0491 - val_prec_neutral: 0.5294 - val_prec_over: 0.5000 - val_prec_under: 0.6000 - val_rec_neutral: 0.1561 - val_rec_over: 0.0578 - val_rec_under: 0.0347 - val_top2_acc: 0.8040\n",
      "Epoch 13/30\n",
      "19/19 - 1s - 48ms/step - acc: 0.7183 - loss: 0.7952 - prec_neutral: 0.4837 - prec_over: 0.7157 - prec_under: 0.5888 - rec_neutral: 0.2853 - rec_over: 0.2388 - rec_under: 0.2747 - top2_acc: 0.9308 - val_acc: 0.4884 - val_loss: 1.0394 - val_prec_neutral: 0.5167 - val_prec_over: 0.5417 - val_prec_under: 0.6471 - val_rec_neutral: 0.1792 - val_rec_over: 0.0751 - val_rec_under: 0.0636 - val_top2_acc: 0.8073\n",
      "Epoch 14/30\n",
      "19/19 - 1s - 46ms/step - acc: 0.7158 - loss: 0.7902 - prec_neutral: 0.6676 - prec_over: 0.5175 - prec_under: 0.7771 - rec_neutral: 0.3051 - rec_over: 0.2612 - rec_under: 0.2659 - top2_acc: 0.9342 - val_acc: 0.4983 - val_loss: 1.0316 - val_prec_neutral: 0.5217 - val_prec_over: 0.5385 - val_prec_under: 0.6000 - val_rec_neutral: 0.2081 - val_rec_over: 0.0809 - val_rec_under: 0.0694 - val_top2_acc: 0.8140\n",
      "Epoch 15/30\n",
      "19/19 - 1s - 45ms/step - acc: 0.7325 - loss: 0.7456 - prec_neutral: 0.7751 - prec_over: 0.7249 - prec_under: 0.5799 - rec_neutral: 0.3030 - rec_over: 0.2545 - rec_under: 0.2849 - top2_acc: 0.9392 - val_acc: 0.5083 - val_loss: 1.0241 - val_prec_neutral: 0.5395 - val_prec_over: 0.5556 - val_prec_under: 0.5417 - val_rec_neutral: 0.2370 - val_rec_over: 0.0867 - val_rec_under: 0.0751 - val_top2_acc: 0.8239\n",
      "Epoch 16/30\n",
      "19/19 - 1s - 44ms/step - acc: 0.7425 - loss: 0.7363 - prec_neutral: 0.5574 - prec_over: 0.7981 - prec_under: 0.6094 - rec_neutral: 0.2898 - rec_over: 0.2677 - rec_under: 0.2593 - top2_acc: 0.9342 - val_acc: 0.5083 - val_loss: 1.0173 - val_prec_neutral: 0.5488 - val_prec_over: 0.6129 - val_prec_under: 0.5714 - val_rec_neutral: 0.2601 - val_rec_over: 0.1098 - val_rec_under: 0.0925 - val_top2_acc: 0.8372\n",
      "Epoch 17/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.7700 - loss: 0.6785 - prec_neutral: 0.6892 - prec_over: 0.5633 - prec_under: 0.6667 - rec_neutral: 0.3125 - rec_over: 0.2718 - rec_under: 0.2794 - top2_acc: 0.9467 - val_acc: 0.5216 - val_loss: 1.0119 - val_prec_neutral: 0.5176 - val_prec_over: 0.5676 - val_prec_under: 0.5405 - val_rec_neutral: 0.2543 - val_rec_over: 0.1214 - val_rec_under: 0.1156 - val_top2_acc: 0.8306\n",
      "Epoch 18/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.7708 - loss: 0.6824 - prec_neutral: 0.6941 - prec_over: 0.5475 - prec_under: 0.6727 - rec_neutral: 0.3309 - rec_over: 0.2703 - rec_under: 0.2692 - top2_acc: 0.9475 - val_acc: 0.5316 - val_loss: 1.0040 - val_prec_neutral: 0.5114 - val_prec_over: 0.6000 - val_prec_under: 0.5610 - val_rec_neutral: 0.2601 - val_rec_over: 0.1387 - val_rec_under: 0.1329 - val_top2_acc: 0.8405\n",
      "Epoch 19/30\n",
      "19/19 - 1s - 45ms/step - acc: 0.7967 - loss: 0.6255 - prec_neutral: 0.7462 - prec_over: 0.7855 - prec_under: 0.4487 - rec_neutral: 0.3248 - rec_over: 0.2638 - rec_under: 0.2656 - top2_acc: 0.9550 - val_acc: 0.5316 - val_loss: 1.0009 - val_prec_neutral: 0.5169 - val_prec_over: 0.6087 - val_prec_under: 0.5833 - val_rec_neutral: 0.2659 - val_rec_over: 0.1618 - val_rec_under: 0.1618 - val_top2_acc: 0.8372\n",
      "Epoch 20/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.8000 - loss: 0.6193 - prec_neutral: 0.6712 - prec_over: 0.8343 - prec_under: 0.7426 - rec_neutral: 0.3027 - rec_over: 0.2847 - rec_under: 0.2852 - top2_acc: 0.9550 - val_acc: 0.5349 - val_loss: 1.0004 - val_prec_neutral: 0.5319 - val_prec_over: 0.6200 - val_prec_under: 0.5962 - val_rec_neutral: 0.2890 - val_rec_over: 0.1792 - val_rec_under: 0.1792 - val_top2_acc: 0.8405\n",
      "Epoch 21/30\n",
      "19/19 - 1s - 43ms/step - acc: 0.8017 - loss: 0.5907 - prec_neutral: 0.6456 - prec_over: 0.7821 - prec_under: 0.6501 - rec_neutral: 0.3060 - rec_over: 0.2966 - rec_under: 0.2965 - top2_acc: 0.9617 - val_acc: 0.5282 - val_loss: 1.0084 - val_prec_neutral: 0.5200 - val_prec_over: 0.6200 - val_prec_under: 0.5741 - val_rec_neutral: 0.3006 - val_rec_over: 0.1792 - val_rec_under: 0.1792 - val_top2_acc: 0.8472\n",
      "Epoch 22/30\n",
      "19/19 - 1s - 48ms/step - acc: 0.8242 - loss: 0.5642 - prec_neutral: 0.6728 - prec_over: 0.5865 - prec_under: 0.8788 - rec_neutral: 0.3065 - rec_over: 0.2841 - rec_under: 0.2976 - top2_acc: 0.9700 - val_acc: 0.5349 - val_loss: 1.0112 - val_prec_neutral: 0.5243 - val_prec_over: 0.6226 - val_prec_under: 0.5614 - val_rec_neutral: 0.3121 - val_rec_over: 0.1908 - val_rec_under: 0.1850 - val_top2_acc: 0.8505\n",
      "Epoch 23/30\n",
      "19/19 - 1s - 48ms/step - acc: 0.8250 - loss: 0.5464 - prec_neutral: 0.7042 - prec_over: 0.6489 - prec_under: 0.6980 - rec_neutral: 0.3297 - rec_over: 0.3072 - rec_under: 0.2945 - top2_acc: 0.9625 - val_acc: 0.5316 - val_loss: 1.0185 - val_prec_neutral: 0.5091 - val_prec_over: 0.6182 - val_prec_under: 0.5690 - val_rec_neutral: 0.3237 - val_rec_over: 0.1965 - val_rec_under: 0.1908 - val_top2_acc: 0.8505\n",
      "Epoch 24/30\n",
      "19/19 - 1s - 48ms/step - acc: 0.8433 - loss: 0.5126 - prec_neutral: 0.8153 - prec_over: 0.5160 - prec_under: 0.7253 - rec_neutral: 0.3219 - rec_over: 0.2766 - rec_under: 0.3000 - top2_acc: 0.9708 - val_acc: 0.5415 - val_loss: 1.0313 - val_prec_neutral: 0.5217 - val_prec_over: 0.6296 - val_prec_under: 0.5763 - val_rec_neutral: 0.3468 - val_rec_over: 0.1965 - val_rec_under: 0.1965 - val_top2_acc: 0.8538\n",
      "Epoch 25/30\n",
      "19/19 - 1s - 46ms/step - acc: 0.8558 - loss: 0.4815 - prec_neutral: 0.6764 - prec_over: 0.4620 - prec_under: 0.5121 - rec_neutral: 0.3125 - rec_over: 0.2847 - rec_under: 0.3045 - top2_acc: 0.9725 - val_acc: 0.5449 - val_loss: 1.0419 - val_prec_neutral: 0.5339 - val_prec_over: 0.6316 - val_prec_under: 0.5873 - val_rec_neutral: 0.3642 - val_rec_over: 0.2081 - val_rec_under: 0.2139 - val_top2_acc: 0.8505\n"
     ]
    }
   ],
   "source": [
    "layers = tf.keras.layers\n",
    "metrics = tf.keras.metrics\n",
    "\n",
    "# get the number of timesteps, channels, and static feature\n",
    "n_timesteps = X_train_ts.shape[1]\n",
    "n_channels = X_train_ts.shape[2]\n",
    "n_static = X_train_static_proc.shape[1]\n",
    "\n",
    "\n",
    "# time series branch\n",
    "ts_input = tf.keras.Input(shape=(n_timesteps, n_channels), name=\"time_series_input\")\n",
    "\n",
    "# define the time series branch of the convoluted NN\n",
    "# follow similar structure as the neural network trained in part 1\n",
    "# train static branch\n",
    "# add max pooling\n",
    "ts_branch = layers.Conv1D(filters=32, kernel_size=5, activation='relu', padding='causal',\n",
    "                          name='convo_layer_1')(ts_input)\n",
    "ts_branch = layers.BatchNormalization(name='convo_batch_norm_1')(ts_branch)\n",
    "ts_branch = layers.MaxPooling1D(pool_size=2, name='max_pooling')(ts_branch)\n",
    "ts_branch = layers.Conv1D(filters=16, kernel_size=3, activation='relu', \n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(1e-3), padding='causal',\n",
    "                          name='convo_layer_2')(ts_branch)\n",
    "ts_branch = layers.BatchNormalization(name='convo_batch_norm_2')(ts_branch)\n",
    "ts_branch = layers.GlobalAveragePooling1D(name='global_average_pooling')(ts_branch)\n",
    "ts_branch = layers.Dropout(0.15, name='convo_dropout')(ts_branch)\n",
    "\n",
    "# now train static branch\n",
    "static_input = tf.keras.Input(shape=(n_static,), name='static_input')\n",
    "# added batch normalization inside raw static input\n",
    "static_branch = layers.BatchNormalization(name='static_batch_norm')(static_input)\n",
    "# reduced dense layer neurons to 128\n",
    "static_branch = layers.Dense(128, activation='relu',\n",
    "                             kernel_regularizer=tf.keras.regularizers.l2(1e-4),\n",
    "                             name='static_dense_layer')(static_branch)\n",
    "static_branch = layers.Dropout(0.2, name='static_dropout')(static_branch)\n",
    "# merge branches\n",
    "merged = layers.Concatenate(name='merge')([ts_branch, static_branch])\n",
    "# add dense layer after merging\n",
    "merged = layers.Dense(64, activation='relu', name='merged_dense_layer')(merged)\n",
    "merged = layers.Dropout(0.3, name='merged_dropout')(merged)\n",
    "output = layers.Dense(3, activation='softmax', name='prediction')(merged)\n",
    "\n",
    "\n",
    "model_conv_ts_static = tf.keras.models.Model(\n",
    "    inputs=[ts_input, static_input],\n",
    "    outputs=output,\n",
    "    name=\"conv1d_ts_plus_static_classifier\"\n",
    ")\n",
    "\n",
    "\n",
    "top2_acc_metric = tf.keras.metrics.SparseTopKCategoricalAccuracy(\n",
    "    k=2,\n",
    "    name=\"top2_accuracy\"\n",
    ")\n",
    "\n",
    "# compile model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_fn   = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model_conv_ts_static.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        metrics.SparseCategoricalAccuracy(name='acc'),\n",
    "        metrics.SparseTopKCategoricalAccuracy(k=2, name='top2_acc'),\n",
    "        metrics.Precision(name='prec_under', class_id=0),\n",
    "        metrics.Recall(name='rec_under', class_id=0),\n",
    "        metrics.Precision(name='prec_neutral', class_id=1),\n",
    "        metrics.Recall(name='rec_neutral', class_id=1),\n",
    "        metrics.Precision(name='prec_over', class_id=2),\n",
    "        metrics.Recall(name='rec_over', class_id=2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# add neutral class weighting\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,   # under\n",
    "    1: 1.3,   # neutral (slightly up-weighted)\n",
    "    2: 1.0    # over\n",
    "}\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# train model\n",
    "history = model_conv_ts_static.fit(\n",
    "    [X_train_ts, X_train_static_proc],  # both inputs\n",
    "    y_train,\n",
    "    validation_data=([X_test_ts, X_test_static_proc], y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    class_weight=class_weight,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02403bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 1s - 55ms/step - acc: 0.5349 - loss: 1.0004 - prec_neutral: 0.6809 - prec_over: 0.6600 - prec_under: 0.7692 - rec_neutral: 0.3122 - rec_over: 0.1719 - rec_under: 0.1688 - top2_acc: 0.8405\n",
      "loss: 1.0004\n",
      "compile_metrics: 0.5349\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "Macro F1: 0.5409\n",
      "Weighted F1: 0.5404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       under       0.60      0.52      0.55        93\n",
      "     neutral       0.42      0.59      0.49       104\n",
      "        over       0.68      0.50      0.58       104\n",
      "\n",
      "    accuracy                           0.53       301\n",
      "   macro avg       0.57      0.53      0.54       301\n",
      "weighted avg       0.57      0.53      0.54       301\n",
      "\n",
      "[[48 40  5]\n",
      " [24 61 19]\n",
      " [ 8 44 52]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keras metrics\n",
    "results = model_conv_ts_static.evaluate(\n",
    "    [X_test_ts, X_test_static_proc],\n",
    "    y_test,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "for name, value in zip(model_conv_ts_static.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# Predictions for sklearn metrics\n",
    "probs = model_conv_ts_static.predict([X_test_ts, X_test_static_proc])\n",
    "pred = probs.argmax(axis=1)\n",
    "\n",
    "macro_f1 = f1_score(y_test, pred, average='macro')\n",
    "weighted_f1 = f1_score(y_test, pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "\n",
    "print(classification_report(\n",
    "    y_test, pred,\n",
    "    target_names=['under', 'neutral', 'over']\n",
    "))\n",
    "\n",
    "print(confusion_matrix(y_test, pred))\n",
    "pd.DataFrame(history.history)[['loss', 'val_loss', 'acc', 'val_acc']].plot(grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea51320c",
   "metadata": {},
   "source": [
    "Now save the model and get the stocks that are most likely to outperform in the next trading day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7028b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "    symbol  over_confidence recommendationKey  currentPrice  forwardPE\n",
      "331   NFLX         0.983647               buy       1112.17  46.769135\n",
      "957   ARWR         0.927669               buy         41.26  -9.777251\n",
      "91     COR         0.923780               buy        361.94  22.123470\n",
      "308    MRK         0.923482               buy         92.92   9.885107\n",
      "264    JNJ         0.914200               buy        195.93  18.483961\n",
      "    p_under  margin_under_vs_next\n",
      "0  0.073268             -0.412959\n",
      "1  0.163022             -0.556540\n",
      "2  0.067744             -0.556890\n",
      "3  0.160065             -0.568843\n",
      "4  0.449732             -0.003156\n",
      "     symbol  under_confidence recommendationKey  currentPrice  forwardPE\n",
      "1427   THRY          0.966578               buy          5.88   7.000000\n",
      "1318   PLAY          0.960635               buy         14.15   3.803763\n",
      "346     NVR          0.920910              none       7271.89  14.037044\n",
      "1284    NWL          0.910765               buy          3.42   4.441559\n",
      "693    IRDM          0.903632              none         16.54  17.229168\n"
     ]
    }
   ],
   "source": [
    "# save final manual model\n",
    "import joblib\n",
    "model_conv_ts_static.save(\"nn_conv_outperf.h5\")\n",
    "joblib.dump(preprocessor, \"preprocessor.pkl\")\n",
    "\n",
    "# Save time-series metadata & scalers used during training\n",
    "joblib.dump(ts_cols_by_group, \"ts_cols_by_group.pkl\")  # dict: group -> column names\n",
    "joblib.dump(scalers_ts, \"scalers_ts.pkl\")              # dict: group -> StandardScaler\n",
    "\n",
    "final_model = tf.keras.models.load_model('nn_conv_outperf.h5')\n",
    "preproc = joblib.load(\"preprocessor.pkl\")\n",
    "ts_cols_by_group = joblib.load(\"ts_cols_by_group.pkl\")\n",
    "scalers_ts = joblib.load(\"scalers_ts.pkl\")\n",
    "\n",
    "df_live = df_cleaned.copy()\n",
    "\n",
    "# Build the list of all time-series columns (same logic as training)\n",
    "ts_all_cols = [c for cols in ts_cols_by_group.values() for c in cols]\n",
    "\n",
    "# STATIC FEATURES: drop label, symbol, and all time-series columns\n",
    "static_live = df_live.drop(columns=['label', 'symbol'] + ts_all_cols, errors='ignore')\n",
    "\n",
    "# Apply static preprocessor\n",
    "X_live_static_proc = preproc.transform(static_live)\n",
    "# If your preprocessor returns sparse matrix, convert to dense\n",
    "if not isinstance(X_live_static_proc, np.ndarray):\n",
    "    X_live_static_proc = X_live_static_proc.toarray()\n",
    "\n",
    "# TIME-SERIES FEATURES: build (n_samples, timesteps, n_channels)\n",
    "ts_live_blocks = []\n",
    "\n",
    "for name, cols in ts_cols_by_group.items():\n",
    "    scaler = scalers_ts[name]\n",
    "    block = df_live[cols]                # shape: (n_samples, timesteps)\n",
    "    block_scaled = scaler.transform(block)\n",
    "    ts_live_blocks.append(block_scaled)\n",
    "\n",
    "n_samples = ts_live_blocks[0].shape[0]\n",
    "n_timesteps = ts_live_blocks[0].shape[1]\n",
    "\n",
    "# reshape each block to (batch, timesteps, 1) and stack as channels\n",
    "live_channels = [b.reshape(n_samples, n_timesteps, 1) for b in ts_live_blocks]\n",
    "X_live_ts = np.concatenate(live_channels, axis=2)   # (n_samples, timesteps, n_channels)\n",
    "\n",
    "# --- predict probabilities over classes ---\n",
    "# model already outputs softmax probabilities, no need for tf.nn.softmax\n",
    "probs = final_model.predict([X_live_ts, X_live_static_proc])\n",
    "\n",
    "p_under = probs[:, 0]\n",
    "p_neut  = probs[:, 1]\n",
    "p_over  = probs[:, 2]\n",
    "\n",
    "# rank the scores\n",
    "df_live['p_over'] = p_over\n",
    "df_live['margin_over_vs_next'] = df_live['p_over'] - np.maximum(p_neut, p_under)\n",
    "df_live['over_confidence'] = df_live[['p_over', 'margin_over_vs_next']].mean(axis=1)\n",
    "\n",
    "# selection rules\n",
    "p_threshold = 0.60\n",
    "stock_picks = df_live.loc[df_live['p_over'] >= p_threshold].copy()\n",
    "top_5 = stock_picks.sort_values('over_confidence', ascending=False).head(5)\n",
    "\n",
    "# print the top 5 and some key metrics\n",
    "print(top_5[['symbol', 'over_confidence', 'recommendationKey', 'currentPrice', 'forwardPE']])\n",
    "\n",
    "# print top 5 to underperform\n",
    "df_live['p_under'] = p_under\n",
    "df_live['margin_under_vs_next'] = df_live['p_under'] - np.maximum(p_neut, p_over)\n",
    "df_live['under_confidence'] = df_live[['p_under', 'margin_under_vs_next']].mean(axis=1)\n",
    "\n",
    "p_threshold = 0.6\n",
    "bottom_picks = df_live.loc[df_live['p_under'] >= p_threshold].copy()\n",
    "bottom_5 = bottom_picks.sort_values('under_confidence', ascending=False).head(5)\n",
    "\n",
    "print(df_live[['p_under', 'margin_under_vs_next']].head())\n",
    "\n",
    "print(bottom_5[['symbol', 'under_confidence','recommendationKey', 'currentPrice', 'forwardPE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52761571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"conv1d_ts_plus_static_classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"conv1d_ts_plus_static_classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ time_series_input   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312</span> │ time_series_inpu… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_batch_norm_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ convo_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ convo_batch_norm… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │ max_pooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4432</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_batch_norm_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │ convo_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_batch_norm   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4432</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,728</span> │ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ convo_batch_norm… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_dense_layer  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">567,424</span> │ static_batch_nor… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_dropout       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_dropout      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ static_dense_lay… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ merge (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ convo_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ static_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ merged_dense_layer  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,280</span> │ merge[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ merged_dropout      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ merged_dense_lay… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │ merged_dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ time_series_input   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m8\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │      \u001b[38;5;34m1,312\u001b[0m │ time_series_inpu… │\n",
       "│ (\u001b[38;5;33mConv1D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_batch_norm_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ convo_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ convo_batch_norm… │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │      \u001b[38;5;34m1,552\u001b[0m │ max_pooling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mConv1D\u001b[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4432\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_batch_norm_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m64\u001b[0m │ convo_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_batch_norm   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4432\u001b[0m)      │     \u001b[38;5;34m17,728\u001b[0m │ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ convo_batch_norm… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_dense_layer  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │    \u001b[38;5;34m567,424\u001b[0m │ static_batch_nor… │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convo_dropout       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ static_dropout      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ static_dense_lay… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ merge (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ convo_dropout[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ static_dropout[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ merged_dense_layer  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m9,280\u001b[0m │ merge[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ merged_dropout      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ merged_dense_lay… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ prediction (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │        \u001b[38;5;34m195\u001b[0m │ merged_dropout[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,775,131</span> (6.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,775,131\u001b[0m (6.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">588,723</span> (2.25 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m588,723\u001b[0m (2.25 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,960</span> (35.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m8,960\u001b[0m (35.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,177,448</span> (4.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,177,448\u001b[0m (4.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show model architecture\n",
    "model_conv_ts_static.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69c674dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted over performance probability\n",
      "[0.27556458 0.28320086 0.20126888 0.14986669 0.5686222  0.15832336\n",
      " 0.17724665 0.19045573 0.6673262  0.49587107]\n",
      "actual value = over perform\n",
      "[0 1 0 0 0 1 0 0 1 0]\n",
      "Bin center p_over≈0.06 -> actual over freq=0.08\n",
      "Bin center p_over≈0.16 -> actual over freq=0.17\n",
      "Bin center p_over≈0.24 -> actual over freq=0.24\n",
      "Bin center p_over≈0.34 -> actual over freq=0.36\n",
      "Bin center p_over≈0.44 -> actual over freq=0.55\n",
      "Bin center p_over≈0.55 -> actual over freq=0.70\n",
      "Bin center p_over≈0.65 -> actual over freq=0.75\n",
      "Bin center p_over≈0.75 -> actual over freq=1.00\n",
      "Bin center p_over≈0.84 -> actual over freq=1.00\n"
     ]
    }
   ],
   "source": [
    "# determine whether p_over actually behaves like 70% overperformance on test set\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# 1) Get probs on the TEST SET using both inputs\n",
    "probs_test = model_conv_ts_static.predict(\n",
    "    [X_test_ts, X_test_static_proc],  # time series + static\n",
    "    batch_size=64,\n",
    "    verbose=0\n",
    ")   # shape: (n_test, 3)\n",
    "\n",
    "# 2) Build binary target for \"over\" class (label=2)\n",
    "y_true_over = (y_test == 2).astype(int)\n",
    "\n",
    "# 3) Extract predicted probability for \"over\"\n",
    "p_over_test = probs_test[:, 2]\n",
    "\n",
    "# 4) Compute calibration curve\n",
    "frac_pos, mean_pred = calibration_curve(y_true_over, p_over_test, n_bins=10)\n",
    "\n",
    "print('predicted over performance probability')\n",
    "print(p_over_test[:10])\n",
    "print('actual value = over perform')\n",
    "print(y_true_over[:10])\n",
    "\n",
    "for m, f in zip(mean_pred, frac_pos):\n",
    "    print(f\"Bin center p_over≈{m:.2f} -> actual over freq={f:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9296faf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recommendations\n",
      "0     buy\n",
      "1    hold\n",
      "2     buy\n",
      "3     buy\n",
      "4     buy\n",
      "Name: recommendationKey, dtype: object\n",
      "probability of overperforming\n",
      "0    0.486227\n",
      "1    0.117416\n",
      "2    0.307621\n",
      "3    0.728908\n",
      "4    0.452888\n",
      "Name: p_over, dtype: float32\n",
      "Model says \"overperform\"  False  True \n",
      "Analyst recommendation                \n",
      "buy                         679    152\n",
      "hold                        239     32\n",
      "none                        175     30\n",
      "sell                          1      0\n",
      "strong_buy                  140     44\n",
      "underperform                  6      3\n"
     ]
    }
   ],
   "source": [
    "print(\"recommendations\")\n",
    "print(df_live['recommendationKey'].head())\n",
    "print('probability of overperforming')\n",
    "print(df_live['p_over'].head())\n",
    "crosstab = pd.crosstab(\n",
    "    df_live['recommendationKey'],\n",
    "    df_live['p_over'] >= 0.6,\n",
    "    rownames=['Analyst recommendation'],\n",
    "    colnames=['Model says \"overperform\"']\n",
    ")\n",
    "print(crosstab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
