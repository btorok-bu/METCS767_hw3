{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26faf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--csv CSV] [--symbol-col SYMBOL_COL]\n",
      "                             [--out-csv OUT_CSV] [--workers WORKERS]\n",
      "                             [--ref-date REF_DATE] [--n-days N_DAYS]\n",
      "                             [--lookback-days LOOKBACK_DAYS] [--verbose]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/brendantorok/Library/Jupyter/runtime/kernel-v37b4f5183853663b8ffa040766db8e1ada0352761.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "CSV_PATH = \"sp1500_tickers_list.csv\"      # input CSV with a 'symbol' column\n",
    "SYMBOL_COL = \"symbol\"                     # column name containing tickers\n",
    "OUT_CSV = \"sp1500_history_30d.csv\"        # output CSV for price history\n",
    "\n",
    "N_DAYS = 30                               # number of trading days to keep per symbol\n",
    "LOOKBACK_DAYS = 90                        # calendar days window to request from Massive\n",
    "WORKERS = 20                              # max parallel threads\n",
    "REF_DATE_STR = None                       # e.g. \"2025-01-15\" or None for \"today UTC\"\n",
    "\n",
    "# Massive API config\n",
    "BASE = \"https://api.massive.com\"\n",
    "TIMESPAN = \"day\"\n",
    "MULTIPLIER = 1\n",
    "LIMIT = 50000\n",
    "ADJUSTED = True\n",
    "SORT = \"asc\"\n",
    "\n",
    "\n",
    "def iso_date(dt_utc: datetime) -> str:\n",
    "    \"\"\"Format a timezone-aware datetime as YYYY-MM-DD.\"\"\"\n",
    "    return dt_utc.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def human_date(ms: int) -> str:\n",
    "    \"\"\"Convert milliseconds since epoch (UTC) to YYYY-MM-DD.\"\"\"\n",
    "    return datetime.fromtimestamp(ms / 1000, tz=timezone.utc).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def fetch_aggs(api_key: str, ticker: str, start_iso: str, end_iso: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Fetch daily aggregate bars for a ticker between start_iso and end_iso.\n",
    "    Raises requests.HTTPError on non-200 responses.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE}/v2/aggs/ticker/{ticker}/range/{MULTIPLIER}/{TIMESPAN}/{start_iso}/{end_iso}\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    params = {\n",
    "        \"adjusted\": str(ADJUSTED).lower(),\n",
    "        \"sort\": SORT,\n",
    "        \"limit\": LIMIT,\n",
    "    }\n",
    "\n",
    "    resp = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    return data.get(\"results\") or []\n",
    "\n",
    "\n",
    "def per_ticker_job(\n",
    "    api_key: str,\n",
    "    ticker: str,\n",
    "    ref_dt_utc: datetime,\n",
    "    lookback_days: int,\n",
    "    n_days: int,\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    For a single ticker:\n",
    "        - Fetch daily bars over a calendar window (lookback_days)\n",
    "        - Sort by timestamp and keep the last n_days bars\n",
    "        - Return a list of row dicts, one per trading day\n",
    "    \"\"\"\n",
    "    start_utc = ref_dt_utc - timedelta(days=lookback_days)\n",
    "    start_iso = iso_date(start_utc)\n",
    "    end_iso = iso_date(ref_dt_utc)\n",
    "\n",
    "    bars = fetch_aggs(api_key, ticker, start_iso, end_iso)\n",
    "    if not bars:\n",
    "        return []\n",
    "\n",
    "    # sort ascending by timestamp, then take the last n_days trading sessions\n",
    "    bars.sort(key=lambda b: b[\"t\"])\n",
    "    if len(bars) > n_days:\n",
    "        bars = bars[-n_days:]\n",
    "\n",
    "    rows = []\n",
    "    for b in bars:\n",
    "        rows.append(\n",
    "            {\n",
    "                \"symbol\": ticker,\n",
    "                \"date\": human_date(b[\"t\"]),\n",
    "                \"open\": b.get(\"o\"),\n",
    "                \"high\": b.get(\"h\"),\n",
    "                \"low\": b.get(\"l\"),\n",
    "                \"close\": b.get(\"c\"),\n",
    "                \"volume\": b.get(\"v\"),\n",
    "                \"vwap\": b.get(\"vw\"),\n",
    "            }\n",
    "        )\n",
    "    return rows\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Run in the notebook cell\n",
    "# =========================\n",
    "\n",
    "# 1. Set API Key\n",
    "api_key = 'enter_api_key_here'\n",
    "\n",
    "# 2. Load tickers\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    raise FileNotFoundError(f\"CSV file not found: {CSV_PATH}\")\n",
    "\n",
    "df_symbols = pd.read_csv(CSV_PATH)\n",
    "\n",
    "if SYMBOL_COL not in df_symbols.columns:\n",
    "    raise KeyError(\n",
    "        f\"Symbol column '{SYMBOL_COL}' not found. \"\n",
    "        f\"Available columns: {list(df_symbols.columns)}\"\n",
    "    )\n",
    "\n",
    "symbols = (\n",
    "    df_symbols[SYMBOL_COL]\n",
    "    .astype(str)\n",
    "    .str.strip()\n",
    "    .str.upper()\n",
    "    .dropna()\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "if not symbols:\n",
    "    raise RuntimeError(\"No symbols found in input CSV. Nothing to do.\")\n",
    "\n",
    "# 3. Reference date\n",
    "if REF_DATE_STR:\n",
    "    ref_dt_utc = datetime.strptime(REF_DATE_STR, \"%Y-%m-%d\").replace(tzinfo=timezone.utc)\n",
    "else:\n",
    "    ref_dt_utc = datetime.now(timezone.utc)\n",
    "\n",
    "print(\n",
    "    f\"Fetching last {N_DAYS} trading days for {len(symbols)} symbols \"\n",
    "    f\"(lookback {LOOKBACK_DAYS} calendar days, ref={iso_date(ref_dt_utc)})\"\n",
    ")\n",
    "\n",
    "# 4. Parallel fetch\n",
    "all_rows: list[dict] = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=WORKERS) as executor:\n",
    "    futures = {\n",
    "        executor.submit(\n",
    "            per_ticker_job,\n",
    "            api_key,\n",
    "            symbol,\n",
    "            ref_dt_utc,\n",
    "            LOOKBACK_DAYS,\n",
    "            N_DAYS,\n",
    "        ): symbol\n",
    "        for symbol in symbols\n",
    "    }\n",
    "\n",
    "    for fut in as_completed(futures):\n",
    "        symbol = futures[fut]\n",
    "        rows = fut.result()\n",
    "        print(f\"{symbol}: {len(rows)} rows\")\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "if not all_rows:\n",
    "    raise RuntimeError(\"No price data returned for any symbol.\")\n",
    "\n",
    "# 5. Build DataFrame and save\n",
    "out_df = pd.DataFrame(all_rows)\n",
    "out_df.sort_values([\"symbol\", \"date\"], inplace=True)\n",
    "out_df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\n",
    "    f\"\\nWrote price history for {out_df['symbol'].nunique()} symbols \"\n",
    "    f\"and {len(out_df)} total rows to {OUT_CSV}\"\n",
    ")\n",
    "\n",
    "out_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
